[
["introduction.html", "OPEN &amp; REPRODUCIBLE MICROBIOME DATA ANALYSIS SPRING SCHOOL 2018 1 Introduction 1.1 Preparing for the course 1.2 Useful functions/resources 1.3 Focus 1.4 Target audience 1.5 License", " OPEN &amp; REPRODUCIBLE MICROBIOME DATA ANALYSIS SPRING SCHOOL 2018 Sudarshan A. Shetty, Leo Lahti, Gerben DA. Hermes 2018-05-26 1 Introduction Three day spring school on basics of high throughput 16S rRNA gene sequencing data analysis. This spring school is organised in collaboration with VLAG graduate school, Laboratory of Microbiology, Laboratory of Systems and Synthetic Biology, Wageningen University &amp; Research, the Netherlands and Department of Mathematics and Statistics University of Turku, Finland. This year it will be held at Wageningen University &amp; Research. We will cover topics related to basics of sequencing and microbial community analysis. We will use NG-Tax and R based tools like Phyloseq, microbiome and ggplot2 for downstream data analysis and visualization. 1.1 Preparing for the course We recommend using your own laptop. If this is not possible, kindly contact the organizers. Install the following software before the course: R version 3.4 R Studio Download the master brach of the the github repository for the course. Unzip the Microbial-bioinformatics-introductory-course-Material-2018-master.zip folder. open the microbiometutorials.Rproj The script to set-up the RStudio environment with required package installations can be found in the folder named scripts/setup_microbiome_analysis.R. In the image below, there is description of how to run this code. 1.2 Useful functions/resources Base R R Markdown RStudio IDE ggplot2 phyloseq microbiome R graphics cookbook List of R tools for microbiome analysis 1.3 Focus The primary aim is introduce microbial community data analysis. There will be talks and discussion on theory and methodology for analysis of microbial community data. We will cover topics ranging from design of studies, sequencing technologies, importance of controls and standardized DNA processing. Supervised hands-on training covering analyses from raw reads using NG-Tax, downstream analysis in R for exploration and analysis of microbiome sequencing data will be priority. There will be a strong focus on using R, R Studio for moving towards reproducible and open science. 1.4 Target audience Anyone who plans to or is currently doing high throughput microbial community analysis. 1.5 License The 2-Clause BSD License SPDX short identifier: BSD-2-Clause Further resources on the 2-clause BSD license Note: This license has also been called the “Simplified BSD License” and the “FreeBSD License”. See also the 3-clause BSD License. Copyright 2018-2020 Sudarshan A. Shetty and Leo Lahti Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met: Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer. Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution. THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS “AS IS” AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE. "],
["set-up-and-pre-processing.html", "2 Set-up and Pre-processing 2.1 OTU or ASVs or sOTUs 2.2 General overview 2.3 Structure 2.4 Making a phyloseq object 2.5 Read the tree file. 2.6 Merge into phyloseq object. 2.7 Read data from OTU-picking stratergy 2.8 Variablity 2.9 OTU-picking stratergy 2.10 NG-tax stragey", " 2 Set-up and Pre-processing This tutorial will introduce you to basic steps of microbial community analysis. More importantly on how to look at your data and filter appropriately. We will use the Human microbiome project phase I data. 2.1 OTU or ASVs or sOTUs For past few years (maybe decade), identifying Operational taxonomic units from raw sequences used clustering approach. Using 97% identity cut-off was a standard approach and often closed reference OTU picking was accepted in the sicentific community. During the time of the development of tools and bioinformatics approaches this was possibly the best available method. However, as with many other fields of science, the knowledge has been updated. Evolution of bioinformatics approaches is a constant process. Based on current knowledge, the cons of 97% OTU picking stratergy (using clustering approaches) have out-weighed the pros (eg. less time). Recent approaches are now focused towards Amplicon Seuence Variants/sOTUs: * Oligotyping * Deblur * DADA2 * NG-Tax All above approaches have one common theme, they avoid 97% clustering and focus on minor differences (in many cases single nucleotide variations) to identify unique ASVs/sOTU. Note: Some how naming is different and variable. For this purpose and in this book, I will stick to ASVs when data from NG-tax is used. In this, section, we will compare outputs from 97% OTU picking approach and NG-tax approach. The data used here is the 16S rRNA gene variable region (V1-V3) for 97% OTU-pciking. The raw reads were processed using QIIME 1.9.1, SortMeRNA, and OTU picking was done using the closed-reference OTU-picking at 97% identity. For NG-Tax we used the same raw data and processed thorough default settings. Here, we do not aim to bench mark. For this course we aim to show differences between results from two approaches. For down stream analysis of *.biom files we use Phyloseq and microbiome. Kindly cite all the packages and tools that were used in your analysis as listed at the end of each document in sessionInfo. Also make sure that you provide the workflow and scripts you used for analysis atleast as supplementary material with your research article. Check Quick-R. 2.2 General overview 2.3 Structure Let us create few folders to organize the analysis. While this can be personal preference, make sure you write the structure to guide others who do not know your data well. # Create Folders as following #Tables dir.create(&quot;tables&quot;) # Figures dir.create(&quot;figures&quot;) # Phyloseq objects dir.create(&quot;phyobjects&quot;) # Custom codes/notes dir.create(&quot;codes_notes&quot;) Load packages library(microbiome) # data analysis and visualisation library(phyloseq) # also the basis of data object. Data analysis and visualisation library(microbiomeutilities) # some utility tools library(RColorBrewer) # nice color options library(ggpubr) # publication quality figures, based on ggplot2 library(DT) # interactive tables in html and markdown library(data.table) # alternative to data.frame library(dplyr) # data handling 2.4 Making a phyloseq object This is the basis for the analyses demonstrated in this tutorial. In the phyloseq object, information on OTU abundances, taxonomy of OTUs, the phylogenetic tree and metadata is stored. A single object with all this information provides a convinient way of handling, manipulating and visualizing data. For more infromation: phyloseq Please remember that the metadata (i.e. mapping) file has to be in .csv format (columns have sample attributes). The read_phylseq function from microbiome package requires metadata in .csv format. Things to be done in QIIME terminal (if required): Important Note 2: If you have error in loading the biom files stating JSON or HDF5 then you need to convert it in to a JSON format. For this, use the following command within the QIIME terminal and not in R! # biom convert -i NGTaxMerged.biom -o ngtax_json.biom --table-type &quot;OTU table&quot; --to-json For more information on the biom format please click here. Important Note 3: The most recent version of NG-Tax does not have this issue. NOTE The read_phyloseq function can be used for reading other outputs (like .shared and consensus taxonomy files from mothur) into phyloseq object. type ?read_phyloseq in the console pane for more information. If you don’t have your own biom file, we have a test dataset. ## Read input to phyloseq object NOTE: For this tutorial purpose, you need to download the test *.biom file from this link and save it in the input_data folder of this project. NG-Tax output ps.ng.tax &lt;- read_phyloseq(otu.file = &quot;./input_data/humanmicrobiome.biom&quot;, taxonomy.file = NULL, metadata.file = &quot;./input_data/metadata_table.csv&quot;, type = &quot;biom&quot;) ## Time to complete depends on OTU file size Notice above, we use relative path and not D:/myproject/input/mybiom.biom. This is important! With an RStudio project, the project folder is considered the root folder and any folders within this folder will be the branches to access data. Hence, sharing the Rproject folder with your article, users can conviniently re-run your analysis without having to paly around with location of files. 2.5 Read the tree file. Note: Requires a package called ape and the extension has to be “.tre” and not “.tree” (you can just change the name of the file extension) # Load tree file library(ape) ## ## Attaching package: &#39;ape&#39; ## The following object is masked from &#39;package:ggpubr&#39;: ## ## rotate treefile_p1 &lt;- read.tree(&quot;./input_data/humanmicrobiome.tree&quot;) 2.6 Merge into phyloseq object. ps.ng.tax &lt;-merge_phyloseq(ps.ng.tax,treefile_p1) # ps0 is the first phyloseq object. print(ps.ng.tax) ## phyloseq-class experiment-level object ## otu_table() OTU Table: [ 4710 taxa and 474 samples ] ## sample_data() Sample Data: [ 474 samples by 30 sample variables ] ## tax_table() Taxonomy Table: [ 4710 taxa by 6 taxonomic ranks ] ## phy_tree() Phylogenetic Tree: [ 4710 tips and 4709 internal nodes ] rank_names(ps.ng.tax) # we check the taxonomic rank information ## [1] &quot;Domain&quot; &quot;Phylum&quot; &quot;Class&quot; &quot;Order&quot; &quot;Family&quot; &quot;Genus&quot; datatable(tax_table(ps.ng.tax)) # the table is interactive you can scrol and search thorugh it for details. Before that we will clean the taxonomy table. tax_table(ps.ng.tax)[,colnames(tax_table(ps.ng.tax))] &lt;- gsub(tax_table(ps.ng.tax)[,colnames(tax_table(ps.ng.tax))],pattern=&quot;[a-z]__&quot;,replacement=&quot;&quot;) tax_table(ps.ng.tax)[tax_table(ps.ng.tax)[,&quot;Phylum&quot;]== &quot;&quot;,&quot;Phylum&quot;] &lt;- &quot;Unidentified&quot; # save the pseq object saveRDS(ps.ng.tax, &quot;./phyobjects/ps.ng.tax.rds&quot;) 2.7 Read data from OTU-picking stratergy The data for tutorial is stored as *.rds file in the R project input_data folder within the main Microbial-bioinformatics-introductory-course-Material-2018-master folder. The data is from the Human microbiome project phase I data. ps.otu &lt;- readRDS(&quot;./input_data/ps.sub.rds&quot;) #microbiome::write_phyloseq(ps0, &quot;METADATA&quot;) # use print option to see the data saved as phyloseq object. ps.ng.tax &lt;- readRDS(&quot;./phyobjects/ps.ng.tax.rds&quot;) print(ps.otu) ## phyloseq-class experiment-level object ## otu_table() OTU Table: [ 4125 taxa and 474 samples ] ## sample_data() Sample Data: [ 474 samples by 31 sample variables ] ## tax_table() Taxonomy Table: [ 4125 taxa by 7 taxonomic ranks ] ## phy_tree() Phylogenetic Tree: [ 4125 tips and 4124 internal nodes ] As can be seen, there is a difference in the number of OTU identifed by both approaches. NG-Tax has more OTUs identifed even aftering filtering the raw reads for rare sequences. # check for features of data summarize_phyloseq(ps.ng.tax) ## Compositional = NO ## 1] Min. number of reads = 2458 ## 2] Max. number of reads = 115023 ## 3] Total number of reads = 4662317 ## 4] Average number of reads = 9836.11181434599 ## 5] Median number of reads = 8188.5 ## 7] Sparsity = 0.986642120633897 ## 6] Any OTU sum to 1 or less? NO ## 8] Number of singletons = 0 ## 9] Percent of OTUs that are singletons 0 ## 10] Number of sample variables are: 30 ## BarcodeSequence ## LinkerPrimerSequence ## run_prefix ## body_habitat ## body_product ## body_site ## bodysite ## dna_extracted ## elevation ## env ## env_biome ## env_feature ## env_material ## env_package ## geo_loc_name ## host_common_name ## host_scientific_name ## host_subject_id ## host_taxid ## latitude ## longitude ## physical_specimen_location ## physical_specimen_remaining ## psn ## public ## sample_type ## scientific_name ## sequencecenter ## title ## Description summarize_phyloseq(ps.otu) ## Compositional = NO ## 1] Min. number of reads = 2011 ## 2] Max. number of reads = 44106 ## 3] Total number of reads = 2457254 ## 4] Average number of reads = 5184.08016877637 ## 5] Median number of reads = 4328 ## 7] Sparsity = 0.964121212121212 ## 6] Any OTU sum to 1 or less? YES ## 8] Number of singletons = 687 ## 9] Percent of OTUs that are singletons 16.6545454545455 ## 10] Number of sample variables are: 31 ## X.SampleID ## BarcodeSequence ## LinkerPrimerSequence ## run_prefix ## body_habitat ## body_product ## body_site ## bodysite ## dna_extracted ## elevation ## env ## env_biome ## env_feature ## env_material ## env_package ## geo_loc_name ## host_common_name ## host_scientific_name ## host_subject_id ## host_taxid ## latitude ## longitude ## physical_specimen_location ## physical_specimen_remaining ## psn ## public ## sample_type ## scientific_name ## sequencecenter ## title ## Description Notices the Sparsity it is high for both approaches, the data has many zeros. A common property of amplicon based microbiome data generated by sequencing. 2.8 Variablity We will check the spread of variation for taxa identifed using both approaches. Coefficient of variation, i.e. sd(x)/mean(x) is a widely used approach to measure spread in the data. Now plot C.V. p1 &lt;- plot_taxa_cv(ps.ng.tax, plot.type = &quot;scatter&quot;) p1 + scale_x_log10() ## Scale for &#39;x&#39; is already present. Adding another scale for &#39;x&#39;, which ## will replace the existing scale. p2 &lt;- plot_taxa_cv(ps.otu, plot.type = &quot;scatter&quot;) p2+ scale_x_log10() ## Scale for &#39;x&#39; is already present. Adding another scale for &#39;x&#39;, which ## will replace the existing scale. From the above two plots, we see that there are several OTUs which are present in less than 20% samples and have high C.V. The OTU-picking approach seems to be noisy and NG-Tax approach seems to have less noise, although with little high ASVs identified even after filtering for low abundant reads. Thus, the ASVs identified by NG-Tax are of high confidence as they seem to be reprsented by high number of sequences in the raw data. Let us check for distribution of numer of sequences retained after OTU picking anf NG-tax approach. p_seqdepth.otu &lt;- plot_read_distribution(ps.otu, &quot;scientific_name&quot;, &quot;density&quot;) ## [1] &quot;Done plotting&quot; p_seqdepth.ngtax &lt;- plot_read_distribution(ps.ng.tax, &quot;scientific_name&quot;, &quot;density&quot;) ## [1] &quot;Done plotting&quot; print(p_seqdepth.otu) print(p_seqdepth.ngtax) We see a better distribution of reads in NG-Tax data. Moving on to distribution of taxa # We make a data table with information on the OTUs ps0_df_taxa &lt;- data.table(tax_table(ps.ng.tax), ASVabundance = taxa_sums(ps.ng.tax), ASV= taxa_names(ps.ng.tax)) ps0_tax_plot &lt;- ggplot(ps0_df_taxa, aes(ASVabundance)) + geom_histogram() + ggtitle(&quot;Histogram of ASVs (unique sequence) counts (NG-Tax)&quot;) + theme_bw() + scale_x_log10() print(ps0_tax_plot) ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. # We make a data table with information on the OTUs ps1_df_taxa &lt;- data.table(tax_table(ps.otu), OTUabundance = taxa_sums(ps.otu), OTU = taxa_names(ps.otu)) ps1_tax_plot &lt;- ggplot(ps1_df_taxa, aes(OTUabundance)) + geom_histogram() + ggtitle(&quot;Histogram of OTU (unique sequence) counts (OTU-picking 97%)&quot;) + theme_bw() + scale_x_log10() print(ps1_tax_plot) ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. The ASVs distribution is close to normal distribution compared to OTU distribution for 97% otu-picking approach. This has implications in downstream statistical analysis like differential abundance testing (covered on Day3). We can also check for prevalance abundance distribtuion of ASVs and OTUs. p &lt;- plot_taxa_prevalence(ps.ng.tax, &quot;Phylum&quot;) p p2 &lt;- plot_taxa_prevalence(ps.otu, &quot;Phylum&quot;) p2 The ASVs identified by NG-tax at low prevalance are represented by high abundance in the sequencing data. There is a higher chance that these are real observations. Checking for potentially spurious OTUs/ASVs. Usually, we do not expect mitochondria and chloroplast as part of the human microbiome. 2.9 OTU-picking stratergy ps0.1.otu &lt;- subset_taxa(ps.otu, Family != &quot;mitochondria&quot;) print(ps0.1.otu) ## phyloseq-class experiment-level object ## otu_table() OTU Table: [ 3690 taxa and 474 samples ] ## sample_data() Sample Data: [ 474 samples by 31 sample variables ] ## tax_table() Taxonomy Table: [ 3690 taxa by 7 taxonomic ranks ] ## phy_tree() Phylogenetic Tree: [ 3690 tips and 3689 internal nodes ] # also check how many lost ntaxa(ps.otu)-ntaxa(ps0.1.otu) ## [1] 435 2.10 NG-tax stragey ps1.1.ngtax &lt;- subset_taxa(ps.ng.tax, Family != &quot;Mitochondria&quot;) # also check how many lost ntaxa(ps.ng.tax)-ntaxa(ps1.1.ngtax) ## [1] 5 There is large different in the mitochondrial sequences detected by OTU-picking approach and NG-Tax approach. Usually, sequence of mitochondrial and chloroplast origin are present is low abundance. Check how many total reads are there in the NG-tax data set. #total number of reads in the dataset reads_per_asv &lt;- taxa_sums(ps1.1.ngtax) print(sum(reads_per_asv)) ## [1] 4662048 There are 4662048 reads in the total data set. How many ASVs are less than 10 reads and how many reads do they contain? print(length(reads_per_asv[reads_per_asv &lt; 10])) ## [1] 654 print(sum(reads_per_asv[reads_per_asv &lt; 10])) ## [1] 4405 To put this into context; out of the 4705 OTUs, a 654 OTUs contain less than 10 reads, which is: print((654/4705)*100) ## [1] 13.90011 OTU picking approach. #total number of reads in the dataset reads_per_otu &lt;- taxa_sums(ps0.1.otu) print(sum(reads_per_otu)) ## [1] 2398446 There are 2398446 reads in the total data set. How many ASVs are less than 10 reads and how many reads do they contain? print(length(reads_per_otu[reads_per_otu &lt; 10])) ## [1] 1678 print(sum(reads_per_otu[reads_per_otu &lt; 10])) ## [1] 5198 To put this into context; out of the 4405 OTUs, a 654 OTUs contain less than 10 reads, which is: print((1678/3690)*100) ## [1] 45.47425 This is a major drawback of the OTU picking strategy. This percent can be lowered with NG_tax, DADA2, Deblur like approaches. Let us see how many singletons are there? length(which(taxa_sums(ps0.1.otu) &lt;= 1)) ## [1] 613 length(which(taxa_sums(ps1.1.ngtax) &lt;= 1)) ## [1] 0 Let us see how many doubletons are there? length(which(taxa_sums(ps0.1.otu) == 2)) ## [1] 279 length(which(taxa_sums(ps1.1.ngtax) == 2)) ## [1] 0 Let us see how many Singletons and doubletons are there? length(which(taxa_sums(ps0.1.otu) &lt;= 2)) ## [1] 892 Singletons and doubletons round((892/3690)*100, digits = 2) ## [1] 24.17 24.17% of the OTUs are doubletons or singletons. This is suggests that there can be potentially spurious OTUs. It is important to understand that depending on origin of sample, the parameters in NG-tax have to be changed. If you expect your samples to have large diversity of which rare taxa are a major fraction, using less stringent parameters is important. Every data has its own properties. It is commonly observed that a large fraction of taxa are rare. A nice reading for this topic is the review by Michael D. J. Lynch &amp; Josh D. Neufeld Ecology and exploration of the rare biosphere. sessionInfo() ## R version 3.4.4 (2018-03-15) ## Platform: x86_64-w64-mingw32/x64 (64-bit) ## Running under: Windows 10 x64 (build 16299) ## ## Matrix products: default ## ## locale: ## [1] LC_COLLATE=English_United States.1252 ## [2] LC_CTYPE=English_United States.1252 ## [3] LC_MONETARY=English_United States.1252 ## [4] LC_NUMERIC=C ## [5] LC_TIME=English_United States.1252 ## ## attached base packages: ## [1] methods stats graphics grDevices utils datasets base ## ## other attached packages: ## [1] ape_5.1 dplyr_0.7.5 ## [3] data.table_1.11.2 DT_0.4 ## [5] ggpubr_0.1.6 magrittr_1.5 ## [7] RColorBrewer_1.1-2 microbiomeutilities_0.99.0 ## [9] microbiome_1.1.10012 ggplot2_2.2.1.9000 ## [11] phyloseq_1.22.3 ## ## loaded via a namespace (and not attached): ## [1] Biobase_2.38.0 viridis_0.5.1 tidyr_0.8.1 ## [4] jsonlite_1.5 viridisLite_0.3.0 splines_3.4.4 ## [7] foreach_1.4.4 shiny_1.1.0 assertthat_0.2.0 ## [10] stats4_3.4.4 yaml_2.1.19 ggrepel_0.8.0 ## [13] pillar_1.2.2 backports_1.1.2 lattice_0.20-35 ## [16] glue_1.2.0 digest_0.6.15 promises_1.0.1 ## [19] XVector_0.18.0 colorspace_1.3-2 htmltools_0.3.6 ## [22] httpuv_1.4.3 Matrix_1.2-12 plyr_1.8.4 ## [25] pkgconfig_2.0.1 pheatmap_1.0.10 zlibbioc_1.24.0 ## [28] xtable_1.8-2 purrr_0.2.4 scales_0.5.0 ## [31] later_0.7.2 Rtsne_0.13 tibble_1.4.2 ## [34] mgcv_1.8-23 IRanges_2.12.0 withr_2.1.2 ## [37] BiocGenerics_0.24.0 lazyeval_0.2.1 mime_0.5 ## [40] survival_2.41-3 evaluate_0.10.1 nlme_3.1-131.1 ## [43] MASS_7.3-49 vegan_2.5-2 tools_3.4.4 ## [46] stringr_1.3.1 S4Vectors_0.16.0 munsell_0.4.3 ## [49] cluster_2.0.6 bindrcpp_0.2.2 Biostrings_2.46.0 ## [52] ade4_1.7-11 compiler_3.4.4 rlang_0.2.0 ## [55] rhdf5_2.22.0 grid_3.4.4 iterators_1.0.9 ## [58] biomformat_1.6.0 htmlwidgets_1.2 crosstalk_1.0.0 ## [61] igraph_1.2.1 labeling_0.3 rmarkdown_1.9 ## [64] gtable_0.2.0 codetools_0.2-15 multtest_2.34.0 ## [67] reshape2_1.4.3 R6_2.2.2 gridExtra_2.3 ## [70] knitr_1.20 bindr_0.1.1 rprojroot_1.3-2 ## [73] permute_0.9-4 stringi_1.2.2 parallel_3.4.4 ## [76] Rcpp_0.12.17 tidyselect_0.2.4 "],
["alpha-diversities.html", "3 Alpha diversities 3.1 Equal sample sums 3.2 Diversities", " 3 Alpha diversities Alpha diversity measures are used to identify within individual taxa richness and evenness. The commonly used metrics/indices are Shannon, Inverse Simpson, Simpson, Gini, Observed and Chao1. These indices do not take into account the phylogeny of the taxa identified in sequencing. Phylogenetic diversity (Faith’s PD) uses phylogenetic distance to calculate the diversity of a given sample. It is important to note that, alpha diversity indices are sensitive to noise that is inherent to application of polymerase chain reaction and the sequencing errors. One has to consider the sequencing depth (how much of the taxa have been sampled) for each sample. If there is a large difference, then it is important to normalize the samples to equal sampling depth. First we look at the sampling depth (no. of reads per sample). Load packages library(microbiome) # data analysis and visualisation library(phyloseq) # also the basis of data object. Data analysis and visualisation library(microbiomeutilities) # some utility tools library(RColorBrewer) # nice color options library(ggpubr) # publication quality figures, based on ggplot2 library(DT) # interactive tables in html and markdown library(data.table) # alternative to data.frame library(dplyr) # data handling The data for tutorial is stored as *.rds file in the R project phyobjects folder. We will use the filtered phyloseq object from Set-up and Pre-processing section. ps1 &lt;- readRDS(&quot;./phyobjects/ps1.rds&quot;) # use print option to see the data saved as phyloseq object. print(ps1) ## phyloseq-class experiment-level object ## otu_table() OTU Table: [ 3690 taxa and 474 samples ] ## sample_data() Sample Data: [ 474 samples by 31 sample variables ] ## tax_table() Taxonomy Table: [ 3690 taxa by 7 taxonomic ranks ] ## phy_tree() Phylogenetic Tree: [ 3690 tips and 3689 internal nodes ] summary(sample_sums(ps1)) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 1286 3063 4192 5060 5790 41694 As is evident there is a large difference in the number of reads. Minimum is 1286 and maximum is 41694!! There is a ~30X difference! We can plot the rarefaction curve for the observed OTUs in the entire data set. out_tab &lt;- t(abundances(ps1)) p &lt;- vegan::rarecurve(out_tab, step = 50, label = FALSE, sample = min(rowSums(out_tab), col = &quot;blue&quot;, cex = 0.6)) Not all samples are reaching a plateau and that few samples have high number of reads and high number of OTUs. Since we are comparing different body sites, some are expected to have low bacterial load. We will normalize to the lowest depth of at least 2000 reads to keep maximum samples for our anlaysis. This can be varied to remove samples with lower sequencing depth. This decision will depend on the research question being addressed. 3.1 Equal sample sums set.seed(9242) # This will help in reprodcuing the filtering and nomalisation. ps0.rar &lt;- rarefy_even_depth(ps1, sample.size = 2000) ## You set `rngseed` to FALSE. Make sure you&#39;ve set &amp; recorded ## the random seed of your session for reproducibility. ## See `?set.seed` ## ... ## 12 samples removedbecause they contained fewer reads than `sample.size`. ## Up to first five removed samples are: ## 1927.SRS020470.SRX022097.SRR0576631927.SRS049823.SRX020523.SRR0464141927.SRS020119.SRX020676.SRR0478441927.SRS020606.SRX022097.SRR0576631927.SRS011634.SRX020659.SRR047489 ## ... ## 688OTUs were removed because they are no longer ## present in any sample after random subsampling ## ... saveRDS(ps0.rar, &quot;./phyobjects/ps0.rar.rds&quot;) Check how much data you have now ps0.rar &lt;- readRDS(&quot;./phyobjects/ps0.rar.rds&quot;) print(ps0.rar) ## phyloseq-class experiment-level object ## otu_table() OTU Table: [ 3002 taxa and 462 samples ] ## sample_data() Sample Data: [ 462 samples by 31 sample variables ] ## tax_table() Taxonomy Table: [ 3002 taxa by 7 taxonomic ranks ] ## phy_tree() Phylogenetic Tree: [ 3002 tips and 3001 internal nodes ] # quick check for sampling depth barplot(sample_sums(ps0.rar), las =2) # quick check taxa prevalence p.rar &lt;- plot_taxa_prevalence(ps0.rar, &quot;Phylum&quot;) p.rar Compare this to taxa prevalence plot from previous section of the tutorial. Do you see any difference? 3.2 Diversities 3.2.1 Non-phylogenetic diversities For more diversity indices please refer to Microbiome Package Let us calculate diversity. hmp.div &lt;- diversities(ps0.rar, index = &quot;all&quot;) datatable(hmp.div) This is one way to plot the data. # get the metadata out as seprate object hmp.meta &lt;- meta(ps0.rar) # Add the rownames as a new colum for easy integration later. hmp.meta$sam_name &lt;- rownames(hmp.meta) # Add the rownames to diversity table hmp.div$sam_name &lt;- rownames(hmp.div) # merge these two data frames into one div.df &lt;- merge(hmp.div,hmp.meta, by = &quot;sam_name&quot;) # check the tables colnames(div.df) ## [1] &quot;sam_name&quot; &quot;inverse_simpson&quot; ## [3] &quot;gini_simpson&quot; &quot;shannon&quot; ## [5] &quot;fisher&quot; &quot;coverage&quot; ## [7] &quot;X.SampleID&quot; &quot;BarcodeSequence&quot; ## [9] &quot;LinkerPrimerSequence&quot; &quot;run_prefix&quot; ## [11] &quot;body_habitat&quot; &quot;body_product&quot; ## [13] &quot;body_site&quot; &quot;bodysite&quot; ## [15] &quot;dna_extracted&quot; &quot;elevation&quot; ## [17] &quot;env&quot; &quot;env_biome&quot; ## [19] &quot;env_feature&quot; &quot;env_material&quot; ## [21] &quot;env_package&quot; &quot;geo_loc_name&quot; ## [23] &quot;host_common_name&quot; &quot;host_scientific_name&quot; ## [25] &quot;host_subject_id&quot; &quot;host_taxid&quot; ## [27] &quot;latitude&quot; &quot;longitude&quot; ## [29] &quot;physical_specimen_location&quot; &quot;physical_specimen_remaining&quot; ## [31] &quot;psn&quot; &quot;public&quot; ## [33] &quot;sample_type&quot; &quot;scientific_name&quot; ## [35] &quot;sequencecenter&quot; &quot;title&quot; ## [37] &quot;Description&quot; # Now use this data frame to plot p &lt;- ggboxplot(div.df, x = &quot;scientific_name&quot;, y = &quot;shannon&quot;, fill = &quot;scientific_name&quot;, palette = &quot;jco&quot;) p + rotate_x_text() colnames(hmp.div) ## [1] &quot;inverse_simpson&quot; &quot;gini_simpson&quot; &quot;shannon&quot; &quot;fisher&quot; ## [5] &quot;coverage&quot; &quot;sam_name&quot; Alternative way # convert phyloseq object into a long data format. div.df2 &lt;- div.df[,c(&quot;scientific_name&quot;, &quot;inverse_simpson&quot;, &quot;gini_simpson&quot;, &quot;shannon&quot;, &quot;fisher&quot;, &quot;coverage&quot;)] # the names are not pretty. we can replace them colnames(div.df2) &lt;- c(&quot;Location&quot;, &quot;Inverse Simpson&quot;, &quot;Gini-Simpson&quot;, &quot;Shannon&quot;, &quot;Fisher&quot;, &quot;Coverage&quot;) # check colnames(div.df2) ## [1] &quot;Location&quot; &quot;Inverse Simpson&quot; &quot;Gini-Simpson&quot; &quot;Shannon&quot; ## [5] &quot;Fisher&quot; &quot;Coverage&quot; div_df_melt &lt;- reshape2::melt(div.df2) ## Using Location as id variables head(div_df_melt) ## Location variable value ## 1 human gut metagenome Inverse Simpson 18.10774 ## 2 human gut metagenome Inverse Simpson 17.92356 ## 3 human oral metagenome Inverse Simpson 14.38766 ## 4 human oral metagenome Inverse Simpson 12.34309 ## 5 human gut metagenome Inverse Simpson 10.89604 ## 6 human gut metagenome Inverse Simpson 11.31670 The diversity indices are stored under column named variable. # Now use this data frame to plot p &lt;- ggboxplot(div_df_melt, x = &quot;Location&quot;, y = &quot;value&quot;, fill = &quot;Location&quot;, palette = &quot;jco&quot;, legend= &quot;right&quot;, facet.by = &quot;variable&quot;, scales = &quot;free&quot;) p &lt;- p + rotate_x_text() # we will remove the x axis lables p &lt;- p + rremove(&quot;x.text&quot;) p ggsave(&quot;./figures/Diversities.pdf&quot;, height = 4, width = 10) lev &lt;- levels(div_df_melt$Location) # get the variables # make a pairwise list that we want to compare. L.pairs &lt;- combn(seq_along(lev), 2, simplify = FALSE, FUN = function(i)lev[i]) pval &lt;- list(cutpoints = c(0, 0.0001, 0.001, 0.01, 0.05, 0.1, 1), symbols = c(&quot;****&quot;, &quot;***&quot;, &quot;**&quot;, &quot;*&quot;, &quot;n.s&quot;)) p2 &lt;- p + stat_compare_means(comparisons = L.pairs, label = &quot;p.signif&quot;, symnum.args = list(cutpoints = c(0, 0.0001, 0.001, 0.01, 0.05, 0.1, 1), symbols = c(&quot;****&quot;, &quot;***&quot;, &quot;**&quot;, &quot;*&quot;, &quot;n.s&quot;))) print(p2) 3.2.2 Phylogenetic diversity Phylogenetic diversity is calculated using the picante package. library(picante) ps0.rar.otutab &lt;- as.data.frame(ps0.rar@otu_table) ps0.rar.tree &lt;- ps0.rar@phy_tree # hmp.meta from previous code chunks # We first need to check if the tree is rooted or not ps0.rar@phy_tree ## ## Phylogenetic tree with 3002 tips and 3001 internal nodes. ## ## Tip labels: ## 4440970, 627481, 86812, 4442127, 4394095, 32546, ... ## Node labels: ## , , , , , , ... ## ## Rooted; includes branch lengths. # it is a rooted tree df.pd &lt;- pd(t(ps0.rar.otutab), ps0.rar.tree,include.root=T) # t(ou_table) transposes the table for use in picante and the tre file comes from the first code chunck we used to read tree file (see making a phyloseq object section). datatable(df.pd) now we need to plot PD. Check above how to get the metadata file from a phyloseq object. # now we need to plot PD # We will add the results of PD to this file and then plot. hmp.meta$Phylogenetic_Diversity &lt;- df.pd$PD Plot pd.plot &lt;- ggboxplot(hmp.meta, x = &quot;scientific_name&quot;, y = &quot;Phylogenetic_Diversity&quot;, fill = &quot;scientific_name&quot;, palette = &quot;jco&quot;, ylab = &quot;Phylogenetic Diversity&quot;, xlab = &quot;Body site&quot;, legend = &quot;right&quot;) pd.plot &lt;- pd.plot + rotate_x_text() pd.plot + stat_compare_means(comparisons = L.pairs, label = &quot;p.signif&quot;, symnum.args = list(cutpoints = c(0, 0.0001, 0.001, 0.01, 0.05, 0.1, 1), symbols = c(&quot;****&quot;, &quot;***&quot;, &quot;**&quot;, &quot;*&quot;, &quot;n.s&quot;))) NOTE: There are arguments both for and against the use of rarefying to equal library size. The application of normalization method will depend on the type of research question. It is always good to check if there is a correlation between increasing library sizes and richness. Observed OTUs and Phylogenetic diversity can be affected by library sizes. It is always good to check for this before making a choice. lib.div &lt;- diversities(ps1, index = &quot;all&quot;) lib.div2 &lt;- richness(ps1) # let us add library size lib.div$LibrarySize &lt;- sample_sums(ps1) lib.div$Richness &lt;- lib.div2$`0` colnames(lib.div) ## [1] &quot;inverse_simpson&quot; &quot;gini_simpson&quot; &quot;shannon&quot; &quot;fisher&quot; ## [5] &quot;coverage&quot; &quot;LibrarySize&quot; &quot;Richness&quot; ggscatter(lib.div, &quot;LibrarySize&quot;, &quot;shannon&quot;) + stat_cor(method = &quot;pearson&quot;) ggscatter(lib.div, &quot;inverse_simpson&quot;, &quot;LibrarySize&quot;, add = &quot;loess&quot;) + stat_cor(method = &quot;pearson&quot;) ggscatter(lib.div, &quot;Richness&quot;, &quot;LibrarySize&quot;, add = &quot;loess&quot;) + stat_cor(method = &quot;pearson&quot;, label.x = 100, label.y = 50000) sessionInfo() ## R version 3.4.4 (2018-03-15) ## Platform: x86_64-w64-mingw32/x64 (64-bit) ## Running under: Windows 10 x64 (build 16299) ## ## Matrix products: default ## ## locale: ## [1] LC_COLLATE=English_United States.1252 ## [2] LC_CTYPE=English_United States.1252 ## [3] LC_MONETARY=English_United States.1252 ## [4] LC_NUMERIC=C ## [5] LC_TIME=English_United States.1252 ## ## attached base packages: ## [1] methods stats graphics grDevices utils datasets base ## ## other attached packages: ## [1] picante_1.7 nlme_3.1-131.1 ## [3] vegan_2.5-2 lattice_0.20-35 ## [5] permute_0.9-4 ape_5.1 ## [7] dplyr_0.7.5 data.table_1.11.2 ## [9] DT_0.4 ggpubr_0.1.6 ## [11] magrittr_1.5 RColorBrewer_1.1-2 ## [13] microbiomeutilities_0.99.0 microbiome_1.1.10012 ## [15] ggplot2_2.2.1.9000 phyloseq_1.22.3 ## ## loaded via a namespace (and not attached): ## [1] Biobase_2.38.0 viridis_0.5.1 tidyr_0.8.1 ## [4] jsonlite_1.5 viridisLite_0.3.0 splines_3.4.4 ## [7] foreach_1.4.4 shiny_1.1.0 assertthat_0.2.0 ## [10] stats4_3.4.4 yaml_2.1.19 ggrepel_0.8.0 ## [13] pillar_1.2.2 backports_1.1.2 glue_1.2.0 ## [16] digest_0.6.15 ggsignif_0.4.0 promises_1.0.1 ## [19] XVector_0.18.0 colorspace_1.3-2 httpuv_1.4.3 ## [22] htmltools_0.3.6 Matrix_1.2-12 plyr_1.8.4 ## [25] pkgconfig_2.0.1 pheatmap_1.0.10 bookdown_0.7 ## [28] zlibbioc_1.24.0 xtable_1.8-2 purrr_0.2.4 ## [31] scales_0.5.0 later_0.7.2 Rtsne_0.13 ## [34] tibble_1.4.2 mgcv_1.8-23 IRanges_2.12.0 ## [37] withr_2.1.2 BiocGenerics_0.24.0 lazyeval_0.2.1 ## [40] mime_0.5 survival_2.41-3 evaluate_0.10.1 ## [43] MASS_7.3-49 tools_3.4.4 stringr_1.3.1 ## [46] S4Vectors_0.16.0 munsell_0.4.3 ggsci_2.9 ## [49] cluster_2.0.6 bindrcpp_0.2.2 Biostrings_2.46.0 ## [52] ade4_1.7-11 compiler_3.4.4 rlang_0.2.0 ## [55] rhdf5_2.22.0 grid_3.4.4 iterators_1.0.9 ## [58] biomformat_1.6.0 htmlwidgets_1.2 crosstalk_1.0.0 ## [61] igraph_1.2.1 labeling_0.3 rmarkdown_1.9 ## [64] gtable_0.2.0 codetools_0.2-15 multtest_2.34.0 ## [67] reshape2_1.4.3 R6_2.2.2 gridExtra_2.3 ## [70] knitr_1.20 bindr_0.1.1 rprojroot_1.3-2 ## [73] stringi_1.2.2 parallel_3.4.4 Rcpp_0.12.17 ## [76] tidyselect_0.2.4 xfun_0.1 "],
["composition-plots.html", "4 Composition plots 4.1 Barplot counts 4.2 Barplot relative abundance 4.3 Heatmaps", " 4 Composition plots Barplots are a simple way of visualising the composition of your samples. We will use the filtered phyloseq object from Set-up and Pre-processing section. Load packages library(microbiome) # data analysis and visualisation library(phyloseq) # also the basis of data object. Data analysis and visualisation library(RColorBrewer) # nice color options library(ggpubr) # publication quality figures, based on ggplot2 library(dplyr) # data handling ps1 &lt;- readRDS(&quot;./phyobjects/ps.ng.tax.rds&quot;) # use print option to see the data saved as phyloseq object. print(ps1) ## phyloseq-class experiment-level object ## otu_table() OTU Table: [ 4710 taxa and 474 samples ] ## sample_data() Sample Data: [ 474 samples by 30 sample variables ] ## tax_table() Taxonomy Table: [ 4710 taxa by 6 taxonomic ranks ] ## phy_tree() Phylogenetic Tree: [ 4710 tips and 4709 internal nodes ] 4.1 Barplot counts ps1.com &lt;- ps1 taxa_names(ps1.com) &lt;- paste0(&quot;Seq_&quot;, rownames(tax_table(ps1.com))) # We need to set Palette taxic &lt;- as.data.frame(ps1.com@tax_table) # this will help in setting large color options #colourCount = length(unique(taxic$Family)) #define number of variable colors based on number of Family (change the level accordingly to phylum/class/order) #getPalette = colorRampPalette(brewer.pal(12, &quot;Paired&quot;)) # change the palette as well as the number of colors will change according to palette. taxic$OTU &lt;- rownames(taxic) # Add the OTU ids from OTU table into the taxa table at the end. colnames(taxic) # You can see that we now have extra taxonomy levels. ## [1] &quot;Domain&quot; &quot;Phylum&quot; &quot;Class&quot; &quot;Order&quot; &quot;Family&quot; &quot;Genus&quot; &quot;OTU&quot; taxmat &lt;- as.matrix(taxic) # convert it into a matrix. new.tax &lt;- tax_table(taxmat) # convert into phyloseq compatible file. tax_table(ps1.com) &lt;- new.tax # incroporate into phyloseq Object # now edit the unclassified taxa tax_table(ps1.com)[tax_table(ps1.com)[, &quot;Family&quot;] == &quot;&quot;, &quot;Family&quot;] &lt;- &quot;Unclassified family&quot; # We will also remove the &#39;f__&#39; patterns for cleaner labels # tax_table(ps1.com)[, colnames(tax_table(ps1.com))] &lt;- gsub(tax_table(ps1.com)[, # colnames(tax_table(ps1.com))], pattern = &quot;[a-z]__&quot;, replacement = &quot;&quot;) # it would be nice to have the Taxonomic names in italics. # for that we set this guide_italics &lt;- guides(fill = guide_legend(label.theme = element_text(size = 15, face = &quot;italic&quot;, colour = &quot;Black&quot;, angle = 0))) ## Now we need to plot at family level, We can do it as follows: # first remove the phy_tree ps1.com@phy_tree &lt;- NULL # Second merge at family level ps1.com.fam &lt;- microbiome::aggregate_taxa(ps1.com, &quot;Family&quot;, top = 10) plot.composition.COuntAbun &lt;- plot_composition(ps1.com.fam) + theme(legend.position = &quot;bottom&quot;) + scale_fill_brewer(&quot;Family&quot;, palette = &quot;Paired&quot;) + theme_bw() + theme(axis.text.x = element_text(angle = 90)) + ggtitle(&quot;Relative abundance&quot;) + guide_italics + theme(legend.title = element_text(size=18)) plot.composition.COuntAbun #ggsave(&quot;./Test_Outputfiles/Family_barplot_CountAbundance.pdf&quot;, height = 6, width = 8) This plot is based on the reads per sample. In the next step, we plot the relative abundance. 4.2 Barplot relative abundance Make it relative abundance # the previous pseq object ps1.com.fam is only counts. # Use traqnsform function of microbiome to convert it to rel abun. ps1.com.fam.rel &lt;- microbiome::transform(ps1.com.fam, &quot;compositional&quot;) plot.composition.relAbun &lt;- plot_composition(ps1.com.fam.rel, sample.sort = &quot;scientific_name&quot;, x.label = &quot;env_material&quot;) + theme(legend.position = &quot;bottom&quot;) + scale_fill_brewer(&quot;Family&quot;, palette = &quot;Paired&quot;) + theme_bw() + theme(axis.text.x = element_text(angle = 90)) + ggtitle(&quot;Relative abundance&quot;) + guide_italics + theme(legend.title = element_text(size=18)) plot.composition.relAbun #ggsave(&quot;./figures/Family_barplot_RelAbundance.pdf&quot;, height = 6, width = 8) 4.2.1 Barplot customize data.com &lt;- plot.composition.relAbun$data colnames(data.com) ## [1] &quot;OTU&quot; &quot;Sample&quot; &quot;Abundance&quot; &quot;xlabel&quot; p.com &lt;- ggplot(data.com, aes(x = Sample, y = Abundance, fill = OTU)) p.com &lt;- p.com + geom_bar(position = &quot;stack&quot;, stat = &quot;identity&quot;) p.com &lt;- p.com + scale_x_discrete(labels = data.com$xlabel, breaks = data.com$Sample) p.com &lt;- p.com + facet_grid(~xlabel, scales = &quot;free&quot;) + theme_bw() p.com &lt;- p.com + scale_fill_brewer(&quot;Family&quot;, palette = &quot;Paired&quot;) p.com &lt;- p.com + rremove(&quot;x.text&quot;) ggsave(&quot;./figures/Composition plots.pdf&quot;, height = 4, width = 6) For more information Microbiome tutorial 4.3 Heatmaps These are a good alternative to barplots. # base plot p.heat &lt;- ggplot(data.com, aes(x = Sample, y = OTU)) + geom_tile(aes(fill = Abundance)) # Change color p.heat &lt;- p.heat + scale_fill_distiller(&quot;Abundance&quot;, palette = &quot;RdYlBu&quot;) + theme_bw() # Make bacterial names italics p.heat &lt;- p.heat + theme(axis.text.y = element_text(colour = &#39;black&#39;, size = 10, face = &#39;italic&#39;)) # Make seperate samples based on main varaible p.heat &lt;- p.heat + facet_grid(~xlabel, scales = &quot;free&quot;) + rremove(&quot;x.text&quot;) p.heat &lt;- p.heat + ylab(&quot;Family&quot;) #Clean the x-axis p.heat &lt;- p.heat + theme(axis.title.x=element_blank(), axis.text.x=element_blank(), axis.ticks.x=element_blank()) # Clean the facet label box p.heat &lt;- p.heat + theme(legend.key = element_blank(), strip.background = element_rect(colour=&quot;black&quot;, fill=&quot;white&quot;)) print(p.heat) ggsave(&quot;./figures/Heatmap.pdf&quot;, height = 4, width = 6) # + geom_text(aes(label = round(Abundance)), size = 0.4) Extra Following is an example of customizing the plot using ggpubr. # we use count data at family level from the barplot for counts ps_df &lt;- microbiomeutilities::phy_to_ldf(ps1.com.fam, transform.counts = &quot;compositional&quot;) ## An additonal column Sam_rep with sample names is created for reference purpose colnames(ps_df) ## [1] &quot;OTUID&quot; &quot;Family&quot; ## [3] &quot;OTU&quot; &quot;Sam_rep&quot; ## [5] &quot;Abundance&quot; &quot;BarcodeSequence&quot; ## [7] &quot;LinkerPrimerSequence&quot; &quot;run_prefix&quot; ## [9] &quot;body_habitat&quot; &quot;body_product&quot; ## [11] &quot;body_site&quot; &quot;bodysite&quot; ## [13] &quot;dna_extracted&quot; &quot;elevation&quot; ## [15] &quot;env&quot; &quot;env_biome&quot; ## [17] &quot;env_feature&quot; &quot;env_material&quot; ## [19] &quot;env_package&quot; &quot;geo_loc_name&quot; ## [21] &quot;host_common_name&quot; &quot;host_scientific_name&quot; ## [23] &quot;host_subject_id&quot; &quot;host_taxid&quot; ## [25] &quot;latitude&quot; &quot;longitude&quot; ## [27] &quot;physical_specimen_location&quot; &quot;physical_specimen_remaining&quot; ## [29] &quot;psn&quot; &quot;public&quot; ## [31] &quot;sample_type&quot; &quot;scientific_name&quot; ## [33] &quot;sequencecenter&quot; &quot;title&quot; ## [35] &quot;Description&quot; # this data.frame can be used to customize several plots. # example boxplot at family level p.box &lt;- ggstripchart(ps_df, &quot;scientific_name&quot;, &quot;Abundance&quot;, facet.by = &quot;Family&quot;, color = &quot;body_product&quot;, palette = &quot;jco&quot; ) p.box + rremove(&quot;x.text&quot;) sessionInfo() ## R version 3.4.4 (2018-03-15) ## Platform: x86_64-w64-mingw32/x64 (64-bit) ## Running under: Windows 10 x64 (build 16299) ## ## Matrix products: default ## ## locale: ## [1] LC_COLLATE=English_United States.1252 ## [2] LC_CTYPE=English_United States.1252 ## [3] LC_MONETARY=English_United States.1252 ## [4] LC_NUMERIC=C ## [5] LC_TIME=English_United States.1252 ## ## attached base packages: ## [1] methods stats graphics grDevices utils datasets base ## ## other attached packages: ## [1] bindrcpp_0.2.2 dplyr_0.7.5 ggpubr_0.1.6 ## [4] magrittr_1.5 RColorBrewer_1.1-2 microbiome_1.1.10012 ## [7] ggplot2_2.2.1.9000 phyloseq_1.22.3 ## ## loaded via a namespace (and not attached): ## [1] ggrepel_0.8.0 Rcpp_0.12.17 ## [3] ape_5.1 lattice_0.20-35 ## [5] tidyr_0.8.1 Biostrings_2.46.0 ## [7] assertthat_0.2.0 rprojroot_1.3-2 ## [9] digest_0.6.15 foreach_1.4.4 ## [11] R6_2.2.2 plyr_1.8.4 ## [13] backports_1.1.2 stats4_3.4.4 ## [15] evaluate_0.10.1 pillar_1.2.2 ## [17] zlibbioc_1.24.0 rlang_0.2.0 ## [19] lazyeval_0.2.1 data.table_1.11.2 ## [21] vegan_2.5-2 S4Vectors_0.16.0 ## [23] Matrix_1.2-12 rmarkdown_1.9 ## [25] labeling_0.3 splines_3.4.4 ## [27] Rtsne_0.13 stringr_1.3.1 ## [29] pheatmap_1.0.10 igraph_1.2.1 ## [31] munsell_0.4.3 compiler_3.4.4 ## [33] xfun_0.1 pkgconfig_2.0.1 ## [35] BiocGenerics_0.24.0 multtest_2.34.0 ## [37] mgcv_1.8-23 htmltools_0.3.6 ## [39] biomformat_1.6.0 tidyselect_0.2.4 ## [41] gridExtra_2.3 tibble_1.4.2 ## [43] bookdown_0.7 IRanges_2.12.0 ## [45] codetools_0.2-15 viridisLite_0.3.0 ## [47] permute_0.9-4 withr_2.1.2 ## [49] MASS_7.3-49 grid_3.4.4 ## [51] nlme_3.1-131.1 jsonlite_1.5 ## [53] gtable_0.2.0 scales_0.5.0 ## [55] stringi_1.2.2 XVector_0.18.0 ## [57] reshape2_1.4.3 viridis_0.5.1 ## [59] ggsci_2.9 iterators_1.0.9 ## [61] tools_3.4.4 microbiomeutilities_0.99.0 ## [63] ade4_1.7-11 Biobase_2.38.0 ## [65] glue_1.2.0 purrr_0.2.4 ## [67] parallel_3.4.4 survival_2.41-3 ## [69] yaml_2.1.19 colorspace_1.3-2 ## [71] rhdf5_2.22.0 cluster_2.0.6 ## [73] knitr_1.20 bindr_0.1.1 "],
["beta-diversity-metrics.html", "5 Beta diversity metrics 5.1 Phylogenetic beta-diversity metrics 5.2 Population-level Density landscapes 5.3 PERMANOVA 5.4 Checking the homogeneity condition", " 5 Beta diversity metrics Beta-diversity: Measures for differences between samples from different groups to identify if there are differences in the overall community composition and structure. Load packages and data library(microbiome) # data analysis and visualisation library(phyloseq) # also the basis of data object. Data analysis and visualisation library(RColorBrewer) # nice color options library(ggpubr) # publication quality figures, based on ggplot2 library(dplyr) # data handling For more information: Ordination. Waste Not, Want Not: Why Rarefying Microbiome Data Is Inadmissible. Normalisation and data transformation. What is Constrained and Unconstrained Ordination. Microbiome Datasets Are Compositional: And This Is Not Optional Compositional analysis: a valid approach to analyze microbiome high-throughput sequencing data # read non rarefied data ps1 &lt;- readRDS(&quot;./phyobjects/ps.ng.tax.rds&quot;) # read rarefied data ps0.rar.rds &lt;- readRDS(&quot;./phyobjects/ps0.rar.rds&quot;) # use print option to see the data saved as phyloseq object. 5.1 Phylogenetic beta-diversity metrics 5.1.1 Unweighted Unifrac Unweighted Unifrac is based on presence/absence of different taxa and abundance is not important. However, it is sensitive to the sequencing depth. If a sample is sequenced more than the others then it may have many OTUs (most of them unique) consequently affecting the unifrac dissimilarity estimation. Usually, using subOTU/ASV approaches many singletons/OTUs with very low reads are discarded. If you have you won data you try the following code. For data from NG-tax we will skip this step as we have no singletons. # if we remove OTUs that are detected atleast 10 times in 5% of the samples ps0.rar.filtered &lt;- core(ps0.rar.rds, detection = 10, prevalence = 0.05) summarize_phyloseq(ps0.rar.filtered) # we reduce the sparsity considerably. For data from OTU picking Since the data used here consists of different body sites with distinct biological properties, the results of ordination do not change a lot by filtering “rare” OTUs. Once again, knowing the biology of your samples and making choices rationally and documenting them is crucial. Feel free to use the OTU-picking strategy phyloseq object to investigate yourself. ordu.unwt.uni &lt;- ordinate(ps0.rar.rds, &quot;PCoA&quot;, &quot;unifrac&quot;, weighted=F) # check for Eigen values # barplot(ordu.unwt.uni$values$Eigenvalues[1:10]) unwt.unifrac &lt;- plot_ordination(ps0.rar.rds, ordu.unwt.uni, color=&quot;scientific_name&quot;) unwt.unifrac &lt;- unwt.unifrac + ggtitle(&quot;Unweighted UniFrac&quot;) + geom_point(size = 2) unwt.unifrac &lt;- unwt.unifrac + theme_classic() + scale_color_brewer(&quot;Location&quot;, palette = &quot;Set2&quot;) print(unwt.unifrac) Try repeating the above ordination using non-filtered phyloseq object. 5.1.2 Weighted Unifrac Weighted Unifrac will consider the abundances of different taxa. ps1.rel &lt;- microbiome::transform(ps1, &quot;compositional&quot;) ordu.wt.uni &lt;- ordinate(ps1.rel , &quot;PCoA&quot;, &quot;unifrac&quot;, weighted=T) # check for Eigen values # barplot(ordu.unwt.uni$values$Eigenvalues[1:10]) wt.unifrac &lt;- plot_ordination(ps1.rel, ordu.wt.uni, color=&quot;scientific_name&quot;) wt.unifrac &lt;- wt.unifrac + ggtitle(&quot;Weighted UniFrac&quot;) + geom_point(size = 2) wt.unifrac &lt;- wt.unifrac + theme_classic() + scale_color_brewer(&quot;Location&quot;, palette = &quot;Set2&quot;) print(wt.unifrac) print(wt.unifrac + stat_ellipse()) The figure brings forward an important characteristics of microbiome data called the ‘Horse-shoe effect’. An investigation and explaination for this can be found in the article by Morton JT., et al. 2017 Uncovering the Horseshoe Effect in Microbial Analyses. You can try repeating this analysis with phyloseq object from OTU-picking approach. Another important aspect regarding weighted unifrac is its property of having heavier weights for abundant taxa. To detect changes in moderately abundant lineages, an extenstion called generalized (UniFrac distance)(https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3413390/) has been developed. In this test data, we expect sufficient biological variation in composition between sites and hence, we do not apply GUniFrac. To reiterate: It is crucial to understand the biological features of the samples. Although these are exploratory approaches, it is important to differentiate between biological signal and technical artifacts. 5.2 Population-level Density landscapes p &lt;- plot_landscape(ps1.rel, &quot;NMDS&quot;, &quot;bray&quot;, col = &quot;scientific_name&quot;) + labs(title = paste(&quot;NMDS / Bray-Curtis&quot;)) p &lt;- p + scale_color_brewer(palette = &quot;Dark2&quot;)+ scale_fill_gradient(low = &quot;#e0ecf4&quot;, high = &quot;#6e016b&quot;) ## Scale for &#39;fill&#39; is already present. Adding another scale for &#39;fill&#39;, ## which will replace the existing scale. p Bray-Curtis dissimilarity does not consider phylogenetic relationships between OTUs. There are several distance methods and a list can be obtained by typying ?distanceMethodList in the console pane. Section on multivariate analysis will be discussed on Day3. 5.3 PERMANOVA Permutational multivariate analysis of variance further reading library(vegan) ## Loading required package: permute ## Loading required package: lattice ## This is vegan 2.5-2 metadf &lt;- data.frame(sample_data(ps1.rel)) unifrac.dist &lt;- UniFrac(ps1.rel, weighted = TRUE, normalized = TRUE, parallel = FALSE, fast = TRUE) permanova &lt;- adonis(unifrac.dist ~ scientific_name, data = metadf) permanova ## ## Call: ## adonis(formula = unifrac.dist ~ scientific_name, data = metadf) ## ## Permutation: free ## Number of permutations: 999 ## ## Terms added sequentially (first to last) ## ## Df SumsOfSqs MeanSqs F.Model R2 Pr(&gt;F) ## scientific_name 3 71.912 23.9705 376.03 0.7059 0.001 *** ## Residuals 470 29.960 0.0637 0.2941 ## Total 473 101.872 1.0000 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 5.4 Checking the homogeneity condition Type ?betadisper in R console for more information. ps.disper &lt;- betadisper(unifrac.dist, metadf$scientific_name) permutest(ps.disper, pairwise = TRUE) ## ## Permutation test for homogeneity of multivariate dispersions ## Permutation: free ## Number of permutations: 999 ## ## Response: Distances ## Df Sum Sq Mean Sq F N.Perm Pr(&gt;F) ## Groups 3 1.0014 0.33381 31.889 999 0.001 *** ## Residuals 470 4.9200 0.01047 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Pairwise comparisons: ## (Observed p-value below diagonal, permuted p-value above diagonal) ## human gut metagenome human oral metagenome ## human gut metagenome 1.0000e-03 ## human oral metagenome 8.3027e-05 ## human skin metagenome 2.8177e-06 2.4596e-02 ## human vaginal metagenome 3.1013e-18 1.4078e-10 ## human skin metagenome human vaginal metagenome ## human gut metagenome 1.0000e-03 0.001 ## human oral metagenome 3.2000e-02 0.001 ## human skin metagenome 0.007 ## human vaginal metagenome 7.0275e-03 sessionInfo() ## R version 3.4.4 (2018-03-15) ## Platform: x86_64-w64-mingw32/x64 (64-bit) ## Running under: Windows 10 x64 (build 16299) ## ## Matrix products: default ## ## locale: ## [1] LC_COLLATE=English_United States.1252 ## [2] LC_CTYPE=English_United States.1252 ## [3] LC_MONETARY=English_United States.1252 ## [4] LC_NUMERIC=C ## [5] LC_TIME=English_United States.1252 ## ## attached base packages: ## [1] methods stats graphics grDevices utils datasets base ## ## other attached packages: ## [1] vegan_2.5-2 lattice_0.20-35 permute_0.9-4 ## [4] dplyr_0.7.5 ggpubr_0.1.6 magrittr_1.5 ## [7] RColorBrewer_1.1-2 microbiome_1.1.10012 ggplot2_2.2.1.9000 ## [10] phyloseq_1.22.3 ## ## loaded via a namespace (and not attached): ## [1] tidyselect_0.2.4 xfun_0.1 reshape2_1.4.3 ## [4] purrr_0.2.4 splines_3.4.4 rhdf5_2.22.0 ## [7] colorspace_1.3-2 htmltools_0.3.6 stats4_3.4.4 ## [10] mgcv_1.8-23 yaml_2.1.19 survival_2.41-3 ## [13] rlang_0.2.0 pillar_1.2.2 withr_2.1.2 ## [16] glue_1.2.0 BiocGenerics_0.24.0 bindrcpp_0.2.2 ## [19] foreach_1.4.4 plyr_1.8.4 bindr_0.1.1 ## [22] stringr_1.3.1 zlibbioc_1.24.0 Biostrings_2.46.0 ## [25] munsell_0.4.3 gtable_0.2.0 codetools_0.2-15 ## [28] evaluate_0.10.1 labeling_0.3 Biobase_2.38.0 ## [31] knitr_1.20 IRanges_2.12.0 biomformat_1.6.0 ## [34] parallel_3.4.4 Rcpp_0.12.17 backports_1.1.2 ## [37] scales_0.5.0 S4Vectors_0.16.0 jsonlite_1.5 ## [40] XVector_0.18.0 digest_0.6.15 Rtsne_0.13 ## [43] stringi_1.2.2 bookdown_0.7 grid_3.4.4 ## [46] ade4_1.7-11 rprojroot_1.3-2 tools_3.4.4 ## [49] lazyeval_0.2.1 tibble_1.4.2 cluster_2.0.6 ## [52] tidyr_0.8.1 ape_5.1 pkgconfig_2.0.1 ## [55] MASS_7.3-49 Matrix_1.2-12 data.table_1.11.2 ## [58] assertthat_0.2.0 rmarkdown_1.9 iterators_1.0.9 ## [61] R6_2.2.2 multtest_2.34.0 igraph_1.2.1 ## [64] nlme_3.1-131.1 compiler_3.4.4 "],
["core-microbiota.html", "6 Core microbiota 6.1 Core microbiota anlaysis 6.2 Core abundance and diversity 6.3 Core visualization", " 6 Core microbiota For more information: The adult intestinal core microbiota is determined by analysis depth and health status. Intestinal microbiome landscaping: insight in community assemblage and implications for microbial modulation strategies. Intestinal Microbiota in Healthy Adults: Temporal Analysis Reveals Individual and Common Core and Relation to Intestinal Symptoms. library(microbiome) # data analysis and visualisation library(phyloseq) # also the basis of data object. Data analysis and visualisation library(RColorBrewer) # nice color options library(ggpubr) # publication quality figures, based on ggplot2 library(dplyr) # data handling 6.1 Core microbiota anlaysis We will use the filtered phyloseq object from previous tutorial. We will use the filtered phyloseq object from the first section for pre-processioning. # read non rarefied data ps1 &lt;- readRDS(&quot;./phyobjects/ps.ng.tax.rds&quot;) # use print option to see the data saved as phyloseq object. Subset the data to keep only stool samples. ps1.stool &lt;- subset_samples(ps1, bodysite == &quot;Stool&quot;) # convert to relative abundance ps1.stool.rel &lt;- microbiome::transform(ps1.stool, &quot;compositional&quot;) print(ps1.stool.rel) ## phyloseq-class experiment-level object ## otu_table() OTU Table: [ 4710 taxa and 169 samples ] ## sample_data() Sample Data: [ 169 samples by 30 sample variables ] ## tax_table() Taxonomy Table: [ 4710 taxa by 6 taxonomic ranks ] ## phy_tree() Phylogenetic Tree: [ 4710 tips and 4709 internal nodes ] ps1.stool.rel2 &lt;- prune_taxa(taxa_sums(ps1.stool.rel) &gt; 0, ps1.stool.rel) print(ps1.stool.rel2) ## phyloseq-class experiment-level object ## otu_table() OTU Table: [ 1996 taxa and 169 samples ] ## sample_data() Sample Data: [ 169 samples by 30 sample variables ] ## tax_table() Taxonomy Table: [ 1996 taxa by 6 taxonomic ranks ] ## phy_tree() Phylogenetic Tree: [ 1996 tips and 1995 internal nodes ] Check of the core OTUs core.taxa.standard &lt;- core_members(ps1.stool.rel2, detection = 0.001, prevalence = 50/100) print(core.taxa.standard) ## [1] &quot;94104936&quot; &quot;941049119&quot; &quot;94104948&quot; &quot;94104953&quot; &quot;94104940&quot; ## [6] &quot;94104937&quot; &quot;941049150&quot; &quot;94104955&quot; &quot;941049451&quot; &quot;94104943&quot; ## [11] &quot;941049144&quot; &quot;94104962&quot; &quot;94104956&quot; &quot;94104959&quot; &quot;94104974&quot; ## [16] &quot;941049143&quot; &quot;941049112&quot; &quot;94104958&quot; &quot;941049125&quot; &quot;941049109&quot; ## [21] &quot;94104969&quot; &quot;94104960&quot; &quot;94104968&quot; &quot;941049102&quot; &quot;941049320&quot; ## [26] &quot;94104946&quot; There are 16 OTUs that are core based on the cut-offs for prevalence and detection we choose. However, we only see IDs, not very informative. We can get the classification of these as below. # Extract the taxonomy table taxonomy &lt;- as.data.frame(tax_table(ps1.stool.rel2)) # Subset this taxonomy table to include only core OTUs core_taxa_id &lt;- subset(taxonomy, rownames(taxonomy) %in% core.taxa.standard) DT::datatable(core_taxa_id) 6.2 Core abundance and diversity Total core abundance in each sample (sum of abundances of the core members): core.abundance &lt;- sample_sums(core(ps1.stool.rel2, detection = 0.001, prevalence = 50/100)) DT::datatable(as.data.frame(core.abundance)) 6.3 Core visualization 6.3.1 Core heatmaps This visualization method has been used for instance in Intestinal microbiome landscaping: insight in community assemblage and implications for microbial modulation strategies. Note that you can order the taxa on the heatmap with the order.taxa argument. # Core with compositionals: prevalences &lt;- seq(.05, 1, .05) detections &lt;- 10^seq(log10(1e-3), log10(.2), length = 10) # Also define gray color palette gray &lt;- gray(seq(0,1,length=5)) p.core &lt;- plot_core(ps1.stool.rel2, plot.type = &quot;heatmap&quot;, colours = gray, prevalences = prevalences, detections = detections, min.prevalence = .5) + xlab(&quot;Detection Threshold (Relative Abundance (%))&quot;) print(p.core) # Same with the viridis color palette # color-blind friendly and uniform # options: viridis, magma, plasma, inferno # https://cran.r-project.org/web/packages/viridis/vignettes/intro-to-viridis.html # Also discrete=TRUE versions available library(viridis) ## Loading required package: viridisLite print(p.core + scale_fill_viridis()) ## Scale for &#39;fill&#39; is already present. Adding another scale for &#39;fill&#39;, ## which will replace the existing scale. Color change # Core with compositionals: prevalences &lt;- seq(.05, 1, .05) detections &lt;- 10^seq(log10(1e-3), log10(.2), length = 10) # Also define gray color palette p.core &lt;- plot_core(ps1.stool.rel2, plot.type = &quot;heatmap&quot;, colours = rev(brewer.pal(5, &quot;Spectral&quot;)), prevalences = prevalences, detections = detections, min.prevalence = .5) + xlab(&quot;Detection Threshold (Relative Abundance (%))&quot;) print(p.core) We have a custom script to format this figure which can be found in scripts folder in the RProject. ps1.stool.rel2.f &lt;- microbiomeutilities::format_to_besthit(ps1.stool.rel2) p.core &lt;- plot_core(ps1.stool.rel2.f, plot.type = &quot;heatmap&quot;, colours = rev(brewer.pal(5, &quot;Spectral&quot;)), prevalences = prevalences, detections = detections, min.prevalence = .5) + xlab(&quot;Detection Threshold (Relative Abundance (%))&quot;) print(p.core) plot(p.core + theme(axis.text.y = element_text(face=&quot;italic&quot;))) sessionInfo() ## R version 3.4.4 (2018-03-15) ## Platform: x86_64-w64-mingw32/x64 (64-bit) ## Running under: Windows 10 x64 (build 16299) ## ## Matrix products: default ## ## locale: ## [1] LC_COLLATE=English_United States.1252 ## [2] LC_CTYPE=English_United States.1252 ## [3] LC_MONETARY=English_United States.1252 ## [4] LC_NUMERIC=C ## [5] LC_TIME=English_United States.1252 ## ## attached base packages: ## [1] methods stats graphics grDevices utils datasets base ## ## other attached packages: ## [1] bindrcpp_0.2.2 viridis_0.5.1 viridisLite_0.3.0 ## [4] dplyr_0.7.5 ggpubr_0.1.6 magrittr_1.5 ## [7] RColorBrewer_1.1-2 microbiome_1.1.10012 ggplot2_2.2.1.9000 ## [10] phyloseq_1.22.3 ## ## loaded via a namespace (and not attached): ## [1] Biobase_2.38.0 tidyr_0.8.1 ## [3] jsonlite_1.5 splines_3.4.4 ## [5] foreach_1.4.4 shiny_1.1.0 ## [7] assertthat_0.2.0 stats4_3.4.4 ## [9] ggrepel_0.8.0 yaml_2.1.19 ## [11] pillar_1.2.2 backports_1.1.2 ## [13] lattice_0.20-35 glue_1.2.0 ## [15] digest_0.6.15 promises_1.0.1 ## [17] XVector_0.18.0 colorspace_1.3-2 ## [19] htmltools_0.3.6 httpuv_1.4.3 ## [21] Matrix_1.2-12 plyr_1.8.4 ## [23] microbiomeutilities_0.99.0 pkgconfig_2.0.1 ## [25] pheatmap_1.0.10 bookdown_0.7 ## [27] zlibbioc_1.24.0 xtable_1.8-2 ## [29] purrr_0.2.4 scales_0.5.0 ## [31] later_0.7.2 Rtsne_0.13 ## [33] tibble_1.4.2 mgcv_1.8-23 ## [35] IRanges_2.12.0 DT_0.4 ## [37] withr_2.1.2 BiocGenerics_0.24.0 ## [39] lazyeval_0.2.1 mime_0.5 ## [41] survival_2.41-3 evaluate_0.10.1 ## [43] nlme_3.1-131.1 MASS_7.3-49 ## [45] vegan_2.5-2 tools_3.4.4 ## [47] data.table_1.11.2 stringr_1.3.1 ## [49] S4Vectors_0.16.0 munsell_0.4.3 ## [51] cluster_2.0.6 Biostrings_2.46.0 ## [53] ade4_1.7-11 compiler_3.4.4 ## [55] rlang_0.2.0 rhdf5_2.22.0 ## [57] grid_3.4.4 iterators_1.0.9 ## [59] biomformat_1.6.0 htmlwidgets_1.2 ## [61] crosstalk_1.0.0 igraph_1.2.1 ## [63] labeling_0.3 rmarkdown_1.9 ## [65] gtable_0.2.0 codetools_0.2-15 ## [67] multtest_2.34.0 reshape2_1.4.3 ## [69] R6_2.2.2 gridExtra_2.3 ## [71] knitr_1.20 bindr_0.1.1 ## [73] rprojroot_1.3-2 permute_0.9-4 ## [75] ape_5.1 stringi_1.2.2 ## [77] parallel_3.4.4 Rcpp_0.12.17 ## [79] tidyselect_0.2.4 xfun_0.1 "],
["inference-of-microbial-ecological-networks.html", "7 Inference of Microbial Ecological Networks 7.1 Prepare data for SpiecEasi 7.2 SPIEC-EASI network reconstruction 7.3 Network properties", " 7 Inference of Microbial Ecological Networks More information on SPIEC-EASI. The input for SPIEC-EASI is a counts table. The normalization and tranformation is done by the function. This is very handy tool. This step is heavy on computational memory and slow. Noise filtered OTU-OTU level covariance would be ideal. Load packages and data library(devtools) install_github(&quot;zdk123/SpiecEasi&quot;) # Other packages you need to install are install.packages(&quot;igraph&quot;) install.packages(&quot;intergraph&quot;) install.packages(&quot;GGally&quot;) devtools::install_github(&quot;briatte/ggnet&quot;) install.packages(&quot;network&quot;) install.packages(&quot;ggnetwork&quot;) library(microbiome) # data analysis and visualisation library(phyloseq) # also the basis of data object. Data analysis and visualisation library(RColorBrewer) # nice color options library(ggpubr) # publication quality figures, based on ggplot2 library(dplyr) # data handling library(SpiecEasi) # Network analysis for sparse compositional data library(network) library(intergraph) #devtools::install_github(&quot;briatte/ggnet&quot;) library(ggnet) library(igraph) Read data ps1 &lt;- readRDS(&quot;./phyobjects/ps.ng.tax.rds&quot;) Select only stool samples We will subset our data to include only stool samples. ps1.stool &lt;- subset_samples(ps1, bodysite == &quot;Stool&quot;) For testing reduce the number of OTUs ps1.stool.otu &lt;- prune_taxa(taxa_sums(ps1.stool) &gt; 100, ps1.stool) # Add taxonomic classification to OTU ID ps1.stool.otu.f &lt;- microbiomeutilities::format_to_besthit(ps1.stool.otu) head(tax_table(ps1.stool.otu)) ## Taxonomy Table: [6 taxa by 6 taxonomic ranks]: ## Domain Phylum Class Order ## 9410491526 &quot;Bacteria&quot; &quot;Bacteroidetes&quot; &quot;Bacteroidia&quot; &quot;Bacteroidales&quot; ## 9410491516 &quot;Bacteria&quot; &quot;Bacteroidetes&quot; &quot;Bacteroidia&quot; &quot;Bacteroidales&quot; ## 9410492612 &quot;Bacteria&quot; &quot;Bacteroidetes&quot; &quot;Bacteroidia&quot; &quot;Bacteroidales&quot; ## 9410491521 &quot;Bacteria&quot; &quot;Bacteroidetes&quot; &quot;Bacteroidia&quot; &quot;Bacteroidales&quot; ## 9410491824 &quot;Bacteria&quot; &quot;Bacteroidetes&quot; &quot;Bacteroidia&quot; &quot;Bacteroidales&quot; ## 9410491817 &quot;Bacteria&quot; &quot;Bacteroidetes&quot; &quot;Bacteroidia&quot; &quot;Bacteroidales&quot; ## Family Genus ## 9410491526 &quot;Bacteroidaceae&quot; &quot;Bacteroides&quot; ## 9410491516 &quot;Bacteroidaceae&quot; &quot;Bacteroides&quot; ## 9410492612 &quot;Bacteroidaceae&quot; &quot;Bacteroides&quot; ## 9410491521 &quot;Bacteroidaceae&quot; &quot;Bacteroides&quot; ## 9410491824 &quot;Bacteroidaceae&quot; &quot;Bacteroides&quot; ## 9410491817 &quot;Bacteroidaceae&quot; &quot;Bacteroides&quot; Check the difference in two phyloseq objects. head(tax_table(ps1.stool.otu.f)) 7.1 Prepare data for SpiecEasi The calcualtion of SpiecEasi are time consuming. For this tutorial we will have the necessary input files for SpiecEasi. OTU table Taxonomy table We save it as .rds object. otu.c &lt;- t(otu_table(ps1.stool.otu.f)@.Data) #extract the otu table from phyloseq object tax.c &lt;- as.data.frame(tax_table(ps1.stool.otu.f)@.Data)#extract the taxonomy information head(tax.c) ## Domain Phylum Class ## OTU-9410491526:Bacteroides Bacteria Bacteroidetes Bacteroidia ## OTU-9410491516:Bacteroides Bacteria Bacteroidetes Bacteroidia ## OTU-9410492612:Bacteroides Bacteria Bacteroidetes Bacteroidia ## OTU-9410491521:Bacteroides Bacteria Bacteroidetes Bacteroidia ## OTU-9410491824:Bacteroides Bacteria Bacteroidetes Bacteroidia ## OTU-9410491817:Bacteroides Bacteria Bacteroidetes Bacteroidia ## Order Family Genus ## OTU-9410491526:Bacteroides Bacteroidales Bacteroidaceae Bacteroides ## OTU-9410491516:Bacteroides Bacteroidales Bacteroidaceae Bacteroides ## OTU-9410492612:Bacteroides Bacteroidales Bacteroidaceae Bacteroides ## OTU-9410491521:Bacteroides Bacteroidales Bacteroidaceae Bacteroides ## OTU-9410491824:Bacteroides Bacteroidales Bacteroidaceae Bacteroides ## OTU-9410491817:Bacteroides Bacteroidales Bacteroidaceae Bacteroides ## best_hit ## OTU-9410491526:Bacteroides OTU-9410491526:Bacteroides ## OTU-9410491516:Bacteroides OTU-9410491516:Bacteroides ## OTU-9410492612:Bacteroides OTU-9410492612:Bacteroides ## OTU-9410491521:Bacteroides OTU-9410491521:Bacteroides ## OTU-9410491824:Bacteroides OTU-9410491824:Bacteroides ## OTU-9410491817:Bacteroides OTU-9410491817:Bacteroides # use this only for first attempt to run it on server to save time #saveRDS(otu.c, &quot;input_data/stool.otu.c.rds&quot;) #saveRDS(tax.c, &quot;input_data/stool.tax.c.rds&quot;) 7.2 SPIEC-EASI network reconstruction More information on SPIEC-EASI. This input for SPIEC-EASI is a counts table. The normalization and tranformation is done by the function. This is very handy tool. This step is heavy on computational memory and very slow. For this workshop we have already have the output and will skip this chuck. # In practice, use more repetitions set.seed(1244) net.c &lt;- spiec.easi(otu.c, method=&#39;mb&#39;, icov.select.params=list(rep.num=50)) # reps have to increases for real data # saveRDS(net.c, &quot;input_data/net.c.rds&quot;) #please use more numebr of rep.num (99 or 999) the paraemters ## Create graph object and get edge values We have save the output of net.c to save time The output of spiec.easi is stored in ./input_data/ as stool.net.c.rds. Read this file in R and follow the steps below. # the PC has low processing power, you can read the otuput created by us present in the input_data folder. net.c &lt;- readRDS(&quot;input_data/stool.net.rds&quot;) class(net.c) ## [1] &quot;select&quot; n.c &lt;- symBeta(getOptBeta(net.c)) Add names to IDs We also add abundance values to vertex (nodes). colnames(n.c) &lt;- rownames(n.c) &lt;- colnames(otu.c) vsize &lt;- log2(apply(otu.c, 2, mean)) # add log abundance as properties of vertex/nodes. 7.2.1 Prepare data for plotting stool.ig &lt;- graph.adjacency(n.c, mode=&#39;undirected&#39;, add.rownames = TRUE, weighted = TRUE) stool.ig # we can see all the attributes and weights ## IGRAPH ae7cfb1 UNW- 679 2454 -- ## + attr: name (v/c), TRUE (v/c), weight (e/n) ## + edges from ae7cfb1 (vertex names): ## [1] OTU-9410491526:Bacteroides--OTU-9410491516:Bacteroides ## [2] OTU-9410491526:Bacteroides--OTU-9410491518:Bacteroides ## [3] OTU-9410491526:Bacteroides--OTU-941049327:Bacteroides ## [4] OTU-9410491526:Bacteroides--OTU-941049949:Bacteroides ## [5] OTU-9410491526:Bacteroides--OTU-9410491514:Bacteroides ## [6] OTU-9410491526:Bacteroides--OTU-9410491513:Bacteroides ## [7] OTU-9410491526:Bacteroides--OTU-9410491574:Parasutterella ## [8] OTU-9410491516:Bacteroides--OTU-9410491522:Bacteroides ## + ... omitted several edges #plot(stool.ig) set the layout option # check what is it? ?layout_with_fr coords.fdr = layout_with_fr(stool.ig) 7.2.2 igraph network E(stool.ig)[weight &gt; 0]$color&lt;-&quot;steelblue&quot; #now color the edges based on their values positive is steelblue E(stool.ig)[weight &lt; 0]$color&lt;-&quot;orange&quot; #now color the edges based on their values plot(stool.ig, layout=coords.fdr, vertex.size = 2, vertex.label.cex = 0.5) The visualisation can be enhanced using ggnet R package. stool.net &lt;- asNetwork(stool.ig) network::set.edge.attribute(stool.net, &quot;color&quot;, ifelse(stool.net %e% &quot;weight&quot; &gt; 0, &quot;steelblue&quot;, &quot;orange&quot;)) Start adding taxonomic information. colnames(tax_table(ps1.stool.otu.f)) ## [1] &quot;Domain&quot; &quot;Phylum&quot; &quot;Class&quot; &quot;Order&quot; &quot;Family&quot; &quot;Genus&quot; ## [7] &quot;best_hit&quot; phyla &lt;- map_levels(colnames(otu.c), from = &quot;best_hit&quot;, to = &quot;Phylum&quot;, tax_table(ps1.stool.otu.f)) stool.net %v% &quot;Phylum&quot; &lt;- phyla stool.net %v% &quot;nodesize&quot; &lt;- vsize 7.2.3 Network plot mycolors &lt;- scale_color_manual(values = c(&quot;#a6cee3&quot;, &quot;#1f78b4&quot;, &quot;#b2df8a&quot;, &quot;#33a02c&quot;,&quot;#fb9a99&quot;,&quot;#e31a1c&quot;,&quot;#fdbf6f&quot;,&quot;#ff7f00&quot;,&quot;#cab2d6&quot;,&quot;#6a3d9a&quot;,&quot;#ffff99&quot;,&quot;#b15928&quot;)) p &lt;- ggnet2(stool.net, node.color = &quot;Phylum&quot;, label = TRUE, node.size = &quot;nodesize&quot;, label.size = 2, edge.color = &quot;color&quot;) + guides(color=guide_legend(title=&quot;Phylum&quot;), size = FALSE) + mycolors p This is difficult to interpret. One way is to remove nodes that are connected to few other nodes. We can use degree as a network statisitic. stl.mb &lt;- degree.distribution(stool.ig) plot(0:(length(stl.mb)-1), stl.mb, ylim=c(0,.35), type=&#39;b&#39;, ylab=&quot;Frequency&quot;, xlab=&quot;Degree&quot;, main=&quot;Degree Distributions&quot;) # we will look at only taxa connect more than 10 others p &lt;- ggnet2(stool.net, node.color = &quot;Phylum&quot;, label = TRUE, label.size = 3, edge.color = &quot;color&quot;, size = &quot;degree&quot;, size.min = 10) + guides(color=guide_legend(title=&quot;Phylum&quot;), size = FALSE) + mycolors ## size.min removed 521 nodes out of 679 ## Scale for &#39;colour&#39; is already present. Adding another scale for ## &#39;colour&#39;, which will replace the existing scale. p 7.3 Network properties Check for the number of positive and negative edges. betaMat=as.matrix(symBeta(getOptBeta(net.c))) # We divide by two since an edge is represented by two entries in the matrix. positive=length(betaMat[betaMat&gt;0])/2 negative=length(betaMat[betaMat&lt;0])/2 total=length(betaMat[betaMat!=0])/2 7.3.1 Modularity in networks net.c ## Model: Meinshausen &amp; Buhlmann Graph Estimation (mb) ## selection criterion: stars ## Graph dimension: 679 ## sparsity level 0.01066118 mod.net &lt;- net.c$refit colnames(mod.net) &lt;- rownames(mod.net) &lt;- colnames(otu.c)#you can remove this vsize &lt;- log2(apply(otu.c, 2, mean))# value we may or may not use as vertex.attribute stool.ig.mod &lt;- graph.adjacency(mod.net, mode=&#39;undirected&#39;, add.rownames = TRUE) plot(stool.ig.mod) # we can see all the attributes and weights stool.net.mod &lt;- asNetwork(stool.ig.mod) phyla &lt;- map_levels(colnames(otu.c), from = &quot;best_hit&quot;, to = &quot;Phylum&quot;, tax_table(ps1.stool.otu.f)) stool.net.mod %v% &quot;Phylum&quot; &lt;- phyla stool.net.mod %v% &quot;nodesize&quot; &lt;- vsize 7.3.2 Network plot mycolors &lt;- scale_color_manual(values = c(&quot;#a6cee3&quot;, &quot;#1f78b4&quot;, &quot;#b2df8a&quot;, &quot;#33a02c&quot;,&quot;#fb9a99&quot;,&quot;#e31a1c&quot;,&quot;#fdbf6f&quot;,&quot;#ff7f00&quot;,&quot;#cab2d6&quot;,&quot;#6a3d9a&quot;,&quot;#ffff99&quot;,&quot;#b15928&quot;)) p &lt;- ggnet2(stool.net.mod, node.color = &quot;Phylum&quot;, label = TRUE, node.size = 2, label.size = 2) + guides(color=guide_legend(title=&quot;Phylum&quot;), size = FALSE) + mycolors p Identify modularity in networks. modules =cluster_fast_greedy(stool.ig.mod) print(modules) ## IGRAPH clustering fast greedy, groups: 12, mod: 0.47 ## + groups: ## $`1` ## [1] &quot;OTU-9410492646:Bacteroides&quot; ## [2] &quot;OTU-9410492641:Bacteroides&quot; ## [3] &quot;OTU-9410492645:Bacteroides&quot; ## [4] &quot;OTU-9410491981:Parabacteroides&quot; ## [5] &quot;OTU-9410491974:Bacteroides&quot; ## [6] &quot;OTU-9410491978:Bacteroides&quot; ## [7] &quot;OTU-9410491977:Parabacteroides&quot; ## [8] &quot;OTU-9410491976:Bacteroides&quot; ## [9] &quot;OTU-9410492922:Bacteroides&quot; ## + ... omitted several groups/vertices modularity(modules) ## [1] 0.4725467 V(stool.ig.mod)$color=modules$membership plot(stool.ig.mod, col = modules, vertex.size = 4, vertex.label = NA) stool.net.mod %v% &quot;membership&quot; &lt;- modules$membership p &lt;- ggnet2(stool.net.mod, node.color = &quot;membership&quot;, label = TRUE, node.size = &quot;nodesize&quot;, label.size = 2) + guides(color=guide_legend(title=&quot;membership&quot;), size = FALSE) + mycolors ## Scale for &#39;colour&#39; is already present. Adding another scale for ## &#39;colour&#39;, which will replace the existing scale. p Check which OTUs are part of different modules. modulesOneIndices=which(modules$membership==1) modulesOneOtus=modules$names[modulesOneIndices] modulesTwoIndices=which(modules$membership==2) modulesTwoOtus=modules$names[modulesTwoIndices] modulesThreeIndices=which(modules$membership==3) modulesThreeOtus=modules$names[modulesThreeIndices] modulesFourIndices=which(modules$membership==4) modulesFourOtus=modules$names[modulesFourIndices] modulesFiveIndices=which(modules$membership==5) modulesFiveOtus=modules$names[modulesFiveIndices] modulesSixIndices=which(modules$membership==6) modulesSixOtus=modules$names[modulesSixIndices] print(modulesOneOtus) ## [1] &quot;OTU-9410492646:Bacteroides&quot; ## [2] &quot;OTU-9410492641:Bacteroides&quot; ## [3] &quot;OTU-9410492645:Bacteroides&quot; ## [4] &quot;OTU-9410491981:Parabacteroides&quot; ## [5] &quot;OTU-9410491974:Bacteroides&quot; ## [6] &quot;OTU-9410491978:Bacteroides&quot; ## [7] &quot;OTU-9410491977:Parabacteroides&quot; ## [8] &quot;OTU-9410491976:Bacteroides&quot; ## [9] &quot;OTU-9410492922:Bacteroides&quot; ## [10] &quot;OTU-9410492638:__&quot; ## [11] &quot;OTU-9410492639:__&quot; ## [12] &quot;OTU-941049940:Butyricimonas&quot; ## [13] &quot;OTU-9410491975:Alistipes&quot; ## [14] &quot;OTU-9410491971:Rikenellaceae&quot; ## [15] &quot;OTU-9410491972:Rikenellaceae&quot; ## [16] &quot;OTU-9410492644:Alloprevotella&quot; ## [17] &quot;OTU-9410491758:Alloprevotella&quot; ## [18] &quot;OTU-9410491980:Prevotella&quot; ## [19] &quot;OTU-9410492643:Ruminococcaceae&quot; ## [20] &quot;OTU-9410492640:Ruminococcaceae&quot; ## [21] &quot;OTU-9410492921:Phascolarctobacterium&quot; ## [22] &quot;OTU-9410492647:Phascolarctobacterium&quot; ## [23] &quot;OTU-941049538:Sutterella&quot; ## [24] &quot;OTU-941049552:uncultured&quot; ## [25] &quot;OTU-9410492642:uncultured&quot; 7.3.3 Good reads for ecological networks Using network analysis to explore co-occurrence patterns in soil microbial communities Microbial Co-occurrence Relationships in the Human Microbiome Correlation detection strategies in microbial data sets vary widely in sensitivity and precision sessionInfo() ## R version 3.4.4 (2018-03-15) ## Platform: x86_64-w64-mingw32/x64 (64-bit) ## Running under: Windows 10 x64 (build 16299) ## ## Matrix products: default ## ## locale: ## [1] LC_COLLATE=English_United States.1252 ## [2] LC_CTYPE=English_United States.1252 ## [3] LC_MONETARY=English_United States.1252 ## [4] LC_NUMERIC=C ## [5] LC_TIME=English_United States.1252 ## ## attached base packages: ## [1] methods stats graphics grDevices utils datasets base ## ## other attached packages: ## [1] scales_0.5.0 sna_2.4 statnet.common_4.0.0 ## [4] bindrcpp_0.2.2 igraph_1.2.1 ggnet_0.1.0 ## [7] intergraph_2.0-2 network_1.13.0.1 SpiecEasi_0.1.2 ## [10] dplyr_0.7.5 ggpubr_0.1.6 magrittr_1.5 ## [13] RColorBrewer_1.1-2 microbiome_1.1.10012 ggplot2_2.2.1.9000 ## [16] phyloseq_1.22.3 ## ## loaded via a namespace (and not attached): ## [1] viridis_0.5.1 Biobase_2.38.0 ## [3] tidyr_0.8.1 viridisLite_0.3.0 ## [5] VGAM_1.0-5 jsonlite_1.5 ## [7] splines_3.4.4 foreach_1.4.4 ## [9] assertthat_0.2.0 stats4_3.4.4 ## [11] ggrepel_0.8.0 yaml_2.1.19 ## [13] pillar_1.2.2 backports_1.1.2 ## [15] lattice_0.20-35 glue_1.2.0 ## [17] digest_0.6.15 XVector_0.18.0 ## [19] colorspace_1.3-2 htmltools_0.3.6 ## [21] Matrix_1.2-12 plyr_1.8.4 ## [23] microbiomeutilities_0.99.0 pkgconfig_2.0.1 ## [25] pheatmap_1.0.10 bookdown_0.7 ## [27] zlibbioc_1.24.0 purrr_0.2.4 ## [29] Rtsne_0.13 huge_1.2.7 ## [31] tibble_1.4.2 mgcv_1.8-23 ## [33] IRanges_2.12.0 withr_2.1.2 ## [35] BiocGenerics_0.24.0 lazyeval_0.2.1 ## [37] survival_2.41-3 evaluate_0.10.1 ## [39] nlme_3.1-131.1 MASS_7.3-49 ## [41] vegan_2.5-2 tools_3.4.4 ## [43] data.table_1.11.2 formatR_1.5 ## [45] stringr_1.3.1 S4Vectors_0.16.0 ## [47] munsell_0.4.3 cluster_2.0.6 ## [49] Biostrings_2.46.0 ade4_1.7-11 ## [51] compiler_3.4.4 rlang_0.2.0 ## [53] rhdf5_2.22.0 grid_3.4.4 ## [55] iterators_1.0.9 biomformat_1.6.0 ## [57] rmarkdown_1.9 boot_1.3-20 ## [59] gtable_0.2.0 codetools_0.2-15 ## [61] multtest_2.34.0 reshape2_1.4.3 ## [63] R6_2.2.2 gridExtra_2.3 ## [65] knitr_1.20 bindr_0.1.1 ## [67] rprojroot_1.3-2 permute_0.9-4 ## [69] ape_5.1 stringi_1.2.2 ## [71] parallel_3.4.4 Rcpp_0.12.17 ## [73] tidyselect_0.2.4 xfun_0.1 "],
["differential-abundance-testing-for-univariate-data.html", "8 Differential abundance testing for univariate data 8.1 Load example data 8.2 Visual comparison of two groups 8.3 Statistical comparison of two groups 8.4 Investigate assumptions of the t-test 8.5 Compare results between parametric and non-parametric tests", " 8 Differential abundance testing for univariate data This section covers basic univariate tests for two-group comparison, covering t-test, Wilcoxon test, and multiple testing. You can try out the suggested exercises in the hands-on session. These are followed by example solutions which we will cover in more detail in the class. 8.1 Load example data The following example compares the abundance of a selected bug between two conditions. We assume that the data is already properly normalized. library(microbiome) theme_set(theme_bw(20)) data(dietswap) d &lt;- dietswap # Pick microbial abundances for a given taxonomic group taxa &lt;- &quot;Dialister&quot; # Construct a data.frame with the selected # taxonomic group and grouping df &lt;- data.frame(Abundance = abundances(d)[taxa,], Group = meta(d)$nationality) library(knitr) kable(head(df)) Abundance Group Sample-1 310 AAM Sample-2 1441 AFR Sample-3 356 AFR Sample-4 1528 AFR Sample-5 361 AFR Sample-6 2375 AFR 8.2 Visual comparison of two groups Task: Compare the groups visually Tips: boxplot, density plot, histogram Visualization of the absolute abundances is shown on the left. Let us try the log10 transformation. Now, the data contains many zeros and taking log10 will yield infinite values. Hence we choose the commonly used, although somewhat problematic, log10(1+x) transformation (right). library(ggplot2) p1 &lt;- ggplot(df, aes(x = Group, y = Abundance)) + geom_boxplot() + labs(title = &quot;Absolute abundances&quot;, y = &quot;Abundance (read count)&quot;) # Let us add the log10(1+x) version: df$Log10_Abundance &lt;- log10(1 + df$Abundance) p2 &lt;- ggplot(df, aes(x = Group, y = Log10_Abundance)) + geom_boxplot() + labs(title = &quot;Log10 abundances&quot;, y = &quot;Abundance (log10(1+x) read count)&quot;) library(patchwork) p1 + p2 8.3 Statistical comparison of two groups Task: Test whether abundance differences are statistically significant between the two groups Tips: t-test (t.test); Wilcoxon test (wilcox.test). Find information on how to use by typing help(t.test) or help(wilcox.test); or by looking for examples from the web. The groups seem to differ. First, let us perform the t-test. This is based on Gaussian assumptions. Each group is expected to follow Gaussian distribution. Significance p-value with t-test: print(t.test(Log10_Abundance ~ Group, data = df)$p.value) ## [1] 0.06032956 According to this, the abundances is not significantly different between the two groups (at \\(p&lt;0.05\\) level). 8.4 Investigate assumptions of the t-test Task: Assess whether the abundance data is Gaussian or log-normal within each group You can use for instance histogram (hist) or density plots (plot(density())). Now let us investigate the Gaussian assumption of the t-test in more detail. Let us try another visualization; the density plot. p &lt;- ggplot(df, aes(fill = Group, x = Log10_Abundance)) + geom_density(alpha = 0.5) print(p) Apparently, the data is not even approximately Gaussian distributed. In such cases, a common procedure is to use non-parametric tests. These do not make assumptions of the data distribution but instead compare the ordering of the samples. So, let us look at the significance p-value with Wilcoxon test (log10 data): print(wilcox.test(Log10_Abundance ~ Group, data = df)$p.value) ## [1] 0.01803111 But since the test is non-parametric, we can as well use the original absolute abundances; thelog transformation does not change sample ordering on which the Wilcoxon test is based. Let us verify that the absolute abundances yield the same p-value for Wilcoxon test: print(wilcox.test(Abundance ~ Group, data = df)$p.value) ## [1] 0.01803111 8.5 Compare results between parametric and non-parametric tests Let us compare how much the results would differ in the whole data between t-test (parametric) and Wilcoxon test (non-parametric).To remove non-varying taxa that would demand extra scripting, let us for demonstration purposes now focus on core taxa that are observed in more than 20% of the samples with more than 3 reads. # Core taxa to be tested test.taxa &lt;- core_members(d, prevalence = 20/100, detection = 3) # Calculate p-values with the two different methods for each taxonomic unit pvalue.ttest &lt;- c() pvalue.wilcoxon &lt;- c() for (taxa in test.taxa) { # Create a new data frame for each taxonomic group df &lt;- data.frame(Abundance = abundances(d)[taxa,], Log10_Abundance = log10(1 + abundances(d)[taxa,]), Group = meta(d)$nationality) pvalue.ttest[[taxa]] &lt;- t.test(Log10_Abundance ~ Group, data = df)$p.value pvalue.wilcoxon[[taxa]] &lt;- wilcox.test(Abundance ~ Group, data = df)$p.value } # Arrange the results in a data.frame pvalues &lt;- data.frame(taxon = test.taxa, pvalue.ttest = pvalue.ttest, pvalue.wilcoxon = pvalue.wilcoxon) # Note that multiple testing occurs. # We must correct the p-values. # let us apply the standard Benjamini-Hochberg False Discovery Rate (FDR) # correction pvalues$pvalue.ttest.adjusted &lt;- p.adjust(pvalues$pvalue.ttest) pvalues$pvalue.wilcoxon.adjusted &lt;- p.adjust(pvalues$pvalue.wilcoxon) Compare the distribution of raw and adjusteed p-values. p1 &lt;- ggplot(pvalues, aes(x = pvalue.wilcoxon)) + geom_histogram() + labs(title = &quot;Raw p-values&quot;) + ylim(c(0, 80)) p2 &lt;- ggplot(pvalues, aes(x = pvalue.wilcoxon.adjusted)) + geom_histogram() + labs(title = &quot;Adjusted p-values&quot;) + ylim(c(0, 80)) print(p1 + p2) Now compare these adjusted p-values between t-test and Wilcoxon test. Let us also highlight the p = 0.05 intervals. p &lt;- ggplot(data = pvalues, aes(x = pvalue.ttest.adjusted, y = pvalue.wilcoxon.adjusted)) + geom_text(aes(label = taxon)) + geom_abline(aes(intercept = 0, slope = 1)) + geom_hline(aes(yintercept = 0.05), shape = 2) + geom_vline(aes(xintercept = 0.05), shape = 2) print(p) "],
["linear-models-the-role-of-covariates.html", "9 Linear models: the role of covariates 9.1 Fitting a linear model 9.2 Interpreting linear model output 9.3 Covariate testing", " 9 Linear models: the role of covariates This section provides hands-on introduction to linear (and generalized linear) models. Task Fit linear model to compare abundance between the two groups. You can use functions lm or glm, for instance. 9.1 Fitting a linear model Let us compare two groups with a linear model. We use Log10 abundances since this is closer to the Gaussian assumptions than the absolute count data. Fit a linear model with Gaussian variation as follows: res &lt;- glm(Log10_Abundance ~ Group, data = df, family = &quot;gaussian&quot;) 9.2 Interpreting linear model output Investigate the model coefficients: knitr::kable(summary(res)$coefficients, digits = 5) Estimate Std. Error t value Pr(&gt;|t|) (Intercept) 2.06864 0.01500 137.89729 0.00000 GroupAFR 0.08065 0.02246 3.59001 0.00041 The intercept equals to the mean in the first group: print(mean(subset(df, Group == &quot;AAM&quot;)$Log10_Abundance)) ## [1] 2.068637 The group term equals to the difference between group means: print(mean(subset(df, Group == &quot;AFR&quot;)$Log10_Abundance) - mean(subset(df, Group == &quot;AAM&quot;)$Log10_Abundance)) ## [1] 0.080646 Note that the linear model (default) significance equals to t-test assuming equal variances. print(t.test(Log10_Abundance ~ Group, data = df, var.equal=TRUE)$p.value) ## [1] 0.0004077211 9.3 Covariate testing Task: Investigate how sex and bmi affect the results. An important advantage of linear and generalized linear models, compared to plain t-test is that they allow incorporating additional variables, such as potential confounders (age, BMI, gender..): # Add a covariate: df$sex &lt;- meta(d)$sex df$bmi_group &lt;- meta(d)$bmi_group # Fit the model: res &lt;- glm(Log10_Abundance ~ Group + sex + bmi_group, data = df, family = &quot;gaussian&quot;) We can even include interaction terms: res &lt;- glm(Log10_Abundance ~ Group * sex * bmi_group, data = df, family = &quot;gaussian&quot;) kable(coefficients(res)) x (Intercept) 2.0812548 GroupAFR 0.0233341 sexMale 0.0090777 bmi_groupoverweight -0.0075846 bmi_groupobese -0.0203030 GroupAFR:sexMale 0.0375102 GroupAFR:bmi_groupoverweight -0.0467722 GroupAFR:bmi_groupobese 0.1209742 sexMale:bmi_groupoverweight -0.0295655 sexMale:bmi_groupobese NA GroupAFR:sexMale:bmi_groupoverweight NA GroupAFR:sexMale:bmi_groupobese NA "],
["advanced-models-for-differential-abundance.html", "10 Advanced models for differential abundance 10.1 Particular properties of taxonomic profiling data 10.2 Generalized linear models: a brief overview 10.3 DESeq2: differential abundance testing for sequencing data", " 10 Advanced models for differential abundance GLMs are the basis for advanced testing of differential abundance in sequencing data. This is necessary, as the sequencing data sets deviate from symmetric, continuous, Gaussian assumptions in many ways. 10.1 Particular properties of taxonomic profiling data 10.1.1 Discrete count data Sequencing data consists of discrete counts: print(abundances(d)[1:5,1:3]) ## Sample-1 Sample-2 Sample-3 ## Actinomycetaceae 11 67 21 ## Aerococcus 1 1 1 ## Aeromonas 1 1 1 ## Akkermansia 1167 6127 4235 ## Alcaligenes faecalis et rel. 90 126 188 10.1.2 Sparsity The data is sparse: hist(log10(1 + abundances(d)), 100) 10.1.3 Rarity Long tails of rare taxa: library(reshape2) medians &lt;- apply(abundances(d),1,median)/1e3 A &lt;- melt(abundances(d)) A$Var1 &lt;- factor(A$Var1, levels = rev(names(sort(medians)))) p &lt;- ggplot(A, aes(x = Var1, y = value)) + geom_boxplot() + labs(y = &quot;Abundance (reads)&quot;, x = &quot;Taxonomic Group&quot;) + scale_y_log10() print(p) 10.1.4 Overdispersion Variance exceeds the mean: means &lt;- apply(abundances(d),1,mean) variances &lt;- apply(abundances(d),1,var) # Calculate mean and variance over samples for each taxon library(reshape2) library(dplyr) df &lt;- melt(abundances(d)) names(df) &lt;- c(&quot;Taxon&quot;, &quot;Sample&quot;, &quot;Reads&quot;) df &lt;- df %&gt;% group_by(Taxon) %&gt;% summarise(mean = mean(Reads), variance = var(Reads)) # Illustrate overdispersion library(scales) p &lt;- ggplot(df, aes(x = mean, y = variance)) + geom_point() + geom_abline(aes(intercept = 0, slope = 1)) + scale_x_log10(labels = scales::scientific) + scale_y_log10(labels = scales::scientific) + labs(title = &quot;Overdispersion (variance &gt; mean)&quot;) print(p) 10.2 Generalized linear models: a brief overview Let us briefly discuss the ideas underlying generalized linear models. The Generalized linear model (GLM) allows a richer family of probability distributions to describe the data. Intuitively speaking, GLMs allow the modeling of nonlinear, nonsymmetric, and nongaussian associations. GLMs consist of three elements: A probability distribution for the data (from exponential family) A linear predictor targeting the mean, or expectation: \\(Xb\\) A link function g such that \\(E(Y) = \\mu = g^{-1}(Xb)\\). Let us fit Poisson with (natural) log-link. Fit abundance (read counts) assuming that the data is Poisson distributed, and the logarithm of its mean, or expectation, is obtained with a linear model. We ignore covariates in this example. # Load again the example data d &lt;- dietswap df &lt;- data.frame(Abundance = abundances(d)[taxa,], Group = meta(d)$nationality) res &lt;- glm(Abundance ~ 1, data = df, family = &quot;poisson&quot;) Investigate the model output: knitr::kable(summary(res)$coefficients, digits = 5) Estimate Std. Error z value Pr(&gt;|z|) (Intercept) 5.02355 0.00544 922.6545 0 Note the link between mean and estimated coefficient (\\(\\mu = e^{\\alpha}\\)): mean(df$Abundance) ## [1] 151.9505 exp(coef(res)) ## (Intercept) ## 151.9505 10.3 DESeq2: differential abundance testing for sequencing data DESeq2 analysis can accommodate those particular assumptions about sequencing data. For details, see the original publication. # Start by converting phyloseq object to deseq2 format library(DESeq2) d &lt;- dietswap # Phyloseq data ds2 &lt;- phyloseq_to_deseq2(d, ~ group + nationality) # Run DESeq2 analysis (all taxa at once!) dds &lt;- DESeq(ds2) # Investigate results res &lt;- results(dds) deseq.results &lt;- as.data.frame(res) df &lt;- deseq.results df$taxon &lt;- rownames(df) df &lt;- df %&gt;% arrange(log2FoldChange, padj) # Print the results; flitered and sorted by pvalue and effectsize library(knitr) df &lt;- df %&gt;% filter(pvalue &lt; 0.05 &amp; log2FoldChange &gt; 1.5) %&gt;% arrange(pvalue, log2FoldChange) knitr::kable(df, digits = 5) baseMean log2FoldChange lfcSE stat pvalue padj taxon 1870.08336 1.89495 0.12667 14.95965 0 0 Clostridium difficile et rel. 1015.44245 2.12453 0.18359 11.57241 0 0 Klebisiella pneumoniae et rel. 3335.72902 3.02549 0.28380 10.66044 0 0 Mitsuokella multiacida et rel. 1519.25023 1.60976 0.18026 8.93027 0 0 Enterobacter aerogenes et rel. 2848.86627 1.77112 0.22906 7.73226 0 0 Megasphaera elsdenii et rel. 321.24275 2.86529 0.37602 7.61997 0 0 Serratia 19.97851 2.24305 0.31335 7.15820 0 0 Aquabacterium 173.00079 1.80120 0.26252 6.86114 0 0 Haemophilus For comparison purposes, assess significances and effect sizes based on Wilcoxon test. test.taxa &lt;- taxa(d) pvalue.wilcoxon &lt;- c() foldchange &lt;- c() for (taxa in test.taxa) { # Create a new data frame for each taxonomic group df &lt;- data.frame(Abundance = abundances(d)[taxa,], Log10_Abundance = log10(1 + abundances(d)[taxa,]), Group = meta(d)$nationality) # Calculate pvalue and effect size (difference beween log means) pvalue.wilcoxon[[taxa]] &lt;- wilcox.test(Abundance ~ Group, data = df)$p.value foldchange[[taxa]] &lt;- coef(lm(Log10_Abundance ~ Group, data = df))[[2]] } # Correct p-values for multiple testing pvalue.wilcoxon.adjusted &lt;- p.adjust(pvalue.wilcoxon) par(mfrow = c(1,2)) plot(deseq.results$padj, pvalue.wilcoxon.adjusted, xlab = &quot;DESeq2 adjusted p-value&quot;, ylab = &quot;Wilcoxon adjusted p-value&quot;, main = &quot;P-value comparison&quot;) abline(v = 0.05, h = 0.05, lty = 2) plot(deseq.results$log2FoldChange, foldchange, xlab = &quot;DESeq2&quot;, ylab = &quot;Linear model&quot;, main = &quot;Effect size comparison&quot;) abline(0,1) For systematic comparisons between various methods for differential abundance testing, see this paper. "],
["further-exercises.html", "11 Further exercises", " 11 Further exercises When done with the differential abundance testing examples, you can investigate the use of the following standard methods for microbiome studies. Compositionality effect: compare the effect of CLR transformation (microbiome::clr) on microbiome ordination with PCoA. Prepare PCoA with Bray-Curtis distances for compositional data; and PCoA with euclidean distances for CLR-transformed data (microbiome::transform). For examples, see microbiome tutorial. "]
]
